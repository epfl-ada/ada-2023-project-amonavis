# The Man and the Machines

## Abstract
Did you ever get lost in your Wikipedia session, when a chain reaction in your thoughts lead you from the discography of your favourite artist to the colonial history of Tokelau?
Over the centuries, our personal experiences and the evolution of linguistics made us able to create connections, and we are now reflecting this tendency in knowledge graphs like Wikipedia.
However, among the countless paths connecting two topics, our fallible mind often relies on our biased knowledge to create those connections: this leads us to trace paths that can appear obvious to us, but unnecessarily long or even nonsensical to a machine, which is traditionally seeking the fastest and optimal approach.
The Man and the Machine starts from human navigation paths, defined by the users playing the Wikispeedia game, to then dwell into the navigation ability of the machine, through semantic-distance-based paths and AI models to become more human-minded.

## Research Questions:
* How does semantic distance affect the paths generated by A*, when compared to other distance metrics?
* Can we identify any patterns or recurring structures in the human paths (ie. going for a central hub)?
* Can a machine become more “human-minded” in its navigation across the topics? (ie. can we train an AI model to play Wikispeedia as a human?)
* What insights can we draw from the cases where human paths outperform the machines ones? And viceversa?

## Methods
First of all, we will use NetworkX to create the Wikispeedia graph to work on. After some exploratory analysis, we will clean the dataset from outliers we do not need _(ie. unfinished paths with just one page visited and less than a one minute stay, indicating players who started a game without trying)_. To compute the semantic distances between each page, we will embed each title _(or article content?)_ into a vector, through the language modelling library Word2Vec, and use the cosine similarity as our main similarity metric.
With the semantic distances, we will implement the A* search algorithm to create semantic-based paths and see how would a machine go from a starting node to its target, and the main differences with other kinds of _(unweighted?)_ shortest paths.
Furthermore, given the multitude of navigation paths that are provided along with the Wikispeedia network, we will be able to implement some network machine learning techniques (ie. Graph Neural Networks) to predict human behaviour.
Ultimately, we will compare Men and Machines path structures, with metrics like length, cost or semantic distance, to draw our conclusions.

## Proposed timeline and organisation within the team
* By the end of week 1, we will finish the data cleaning, look for the most appropriate machine learning techniques to work with (according to the efficiency of the models and the technical feasibility based on our expertise) and divide us in two groups: one for the main analyses and one for the machine learning part;
* by the end of week 2, we will answer the first 2 research questions, meaning we will have mastered our way through the dataset;
* by the end of week 3, we will answer the last 2 research questions, meaning we will be done with the prediction part;
* by the end of week 4, we will choose the final plots and elements of the notebook to include in the blog page, for a comprehensive and exhaustive storytelling;
* by the end of week 5, we will do our final reviews of the blog and polish the design for an effective publication and presentation.

## Questions for TAs (optional): 
Add here any questions you have for us related to the proposed project.


