{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Initial machine\n",
    "Objective of this is to build a simple method that runs A* and can find some shortest path between two nodes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "#path = os.path.abspath(\"datasets\")\n",
    "sys.path.append('../')\n",
    "import data_readers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "from scipy.spatial import distance\n",
    "import gensim.downloader\n",
    "import networkx as nx\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "glove_vectors = gensim.downloader.load('glove-twitter-25')\n",
    "\n",
    "# The links and edges\n",
    "wikispeedia= nx.read_edgelist('../datasets/wikispeedia_paths-and-graph/links.tsv',\n",
    "                                    create_using=nx.DiGraph)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f8dbeca595ee4e19a8407e8ee8888c0b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lolco\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\lolco\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0fdcfdc4fd040719c9d08e6b1807363"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7912e766ea645bfaec09d87ad398214"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c87048ca06c42b5b08d7ede157b385e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to get embeddings\n",
    "def get_embedding(text: str):\n",
    "    temp_str = text.replace('_', ' ')\n",
    "    inputs = tokenizer(temp_str, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "# For the heuristic, I need to create a function for two reasons:\n",
    "# A) I need to parse the node and make sure I'm getting the title as the value\n",
    "# B) I need to take care of cases where the word doesn't exist.\n",
    "# Carlos already kinda took care of that!\n",
    "\n",
    "def distance_two_words(w1: str, w2: str):\n",
    "    \"\"\"Receives a string that was in the wikispeedia dataset, and transforms it as needed to work\n",
    "    with word2vec.\n",
    "\n",
    "    Namly, it splits words \"\"\"\n",
    "\n",
    "\n",
    "    embedding1 = get_embedding(w1)\n",
    "    embedding2 = get_embedding(w2)\n",
    "    similarity = cosine_similarity(embedding1.detach().numpy(), embedding2.detach().numpy())[0][0]\n",
    "    # Adding absolute, just in case it is needed\n",
    "    # Similarity is actually 1 - abs(similarity) + 1,\n",
    "    # As we want closer words to have a smaller distance\n",
    "    # The last plus one is to indicate that there would be an extra cost to exploring...\n",
    "    #   not sure if it's needed though...\n",
    "    similarity = 1 -abs(similarity) + 1\n",
    "    # print(\"First word:\", w1, \". Second word:\", w2, \". GoodDistance:\", similarity)\n",
    "    return similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First word: Charles_II_of_England . Second word: Japan . GoodDistance: 1.6090421080589294\n",
      "First word: Drama . Second word: Japan . GoodDistance: 1.309839129447937\n",
      "First word: Film . Second word: Japan . GoodDistance: 1.2666865587234497\n",
      "First word: Greece . Second word: Japan . GoodDistance: 1.2139631509780884\n",
      "First word: H%C3%A4nsel_und_Gretel . Second word: Japan . GoodDistance: 1.7219897210597992\n",
      "First word: Japan . Second word: Japan . GoodDistance: 1.0\n",
      "First word: Latin . Second word: Japan . GoodDistance: 1.27892005443573\n",
      "First word: Middle_Ages . Second word: Japan . GoodDistance: 1.536699801683426\n",
      "First word: Opera . Second word: Japan . GoodDistance: 1.2991307973861694\n",
      "First word: Television . Second word: Japan . GoodDistance: 1.2993553280830383\n",
      "First word: The_Marriage_of_Figaro . Second word: Japan . GoodDistance: 1.5767060220241547\n",
      "First word: The_Simpsons . Second word: Japan . GoodDistance: 1.3803905844688416\n",
      "First word: William_Shakespeare . Second word: Japan . GoodDistance: 1.4377305507659912\n"
     ]
    },
    {
     "data": {
      "text/plain": "['Actor', 'Japan']"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.astar_path(wikispeedia, 'Actor', 'Japan', heuristic=distance_two_words)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Method works, but holy shit it's slow af...\n",
    "\n",
    "The shortest path found tends to be good enough, but it's actually not!\n",
    "\n",
    "This method is finding a path that is shortest than the one described in the shortest path dictionary... how?\n",
    "\n",
    "In the printed example, Actor and Japan are neighbors, but in the dataset it says their distance is of 3!\n",
    "\n",
    "I'll double check the data to see if it's all correct or not"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "AtlasView({'Charles_II_of_England': {}, 'Drama': {}, 'Film': {}, 'Greece': {}, 'H%C3%A4nsel_und_Gretel': {}, 'Japan': {}, 'Latin': {}, 'Middle_Ages': {}, 'Opera': {}, 'Television': {}, 'The_Marriage_of_Figaro': {}, 'The_Simpsons': {}, 'William_Shakespeare': {}})"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikispeedia.adj['Actor']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And japan is a neighbor... great!\n",
    "\n",
    "Proof that this shit is wrong follows, reading in the shortest path df and parsing it as indicated\n",
    "\n",
    "And it's read as well as possible... fuckkkk"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "shortest_path = np.genfromtxt(\"../datasets/wikispeedia_paths-and-graph/shortest-path-distance-matrix.txt\",\n",
    "                                  delimiter=1, missing_values=-1, dtype=int)\n",
    "articles = pd.read_csv('../datasets/wikispeedia_paths-and-graph/articles.tsv', sep='\\t', skiprows=12,\n",
    "                       names=[\"article_name\"])\n",
    "\n",
    "shortest_path_df = pd.DataFrame(shortest_path, index=articles.values, columns=articles.values)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortest_path_df[('Actor',)][('Japan',)]"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
