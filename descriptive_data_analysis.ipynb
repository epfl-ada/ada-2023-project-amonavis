{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How many articles there are, how many paths\n",
    "2. Histograms of the links from each article (for example, how many articles have 20 links, etc)\n",
    "3. Average distance from one article to any other article\n",
    "4. Histogram of the number of games at each point in time. Which categories of games are more likely to be unfished.\n",
    "5. Classify how many times each word appears in the games (we could also do a histogram with that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikispeedia= networkx.read_edgelist('datasets/wikispeedia_paths-and-graph/links.tsv', \n",
    "                                    create_using=networkx.DiGraph)\n",
    "paths_finished = pd.read_csv('datasets/wikispeedia_paths-and-graph/paths_finished.tsv', sep='\\t', skiprows=15, \n",
    "                   names=['hashedIpAddress', 'timestamp', \"durationInSec\", 'path', \"rating\"])\n",
    "paths_unfinished = pd.read_csv('datasets/wikispeedia_paths-and-graph/paths_unfinished.tsv', sep='\\t', skiprows=16,\n",
    "                               names=['hashedIpAddress', 'timestamp', \"durationInSec\", 'path', \"target\", \"type\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How many articles and links are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are\", len(wikispeedia.nodes), \"articles in the dataset.\")\n",
    "print(\"There are\", len(wikispeedia.edges), \"links/paths.\")\n",
    "print(\"There are\", paths_finished.shape[0], \"finished games.\")\n",
    "print(\"There are\", paths_unfinished.shape[0], \"unfinished games.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Degree of a Node\n",
    "The degree of a node is the number of edges/links it has. We plot a complementary cumulative distribution function (CCDF) of degree for each article/node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the degrees of all nodes\n",
    "degrees = dict(wikispeedia.degree())\n",
    "\n",
    "# Calculate the CCDF\n",
    "degree_values = sorted(set(degrees.values()), reverse=True)\n",
    "ccdf = [sum(1 for degree in degrees.values() if degree >= d) for d in degree_values]\n",
    "\n",
    "# Plot the CCDF\n",
    "plt.plot(degree_values, ccdf, marker='o', linestyle='-', color='b')\n",
    "plt.xscale('log')  # Use log scale for better visualization\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Complementary Cumulative Distribution Function (CCDF)')\n",
    "plt.title('CCDF of Node Degrees')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the \"hubs\"? Which nodes have more than 500 links?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nodes with more than 1000 edges: \", [node for node in wikispeedia.nodes if wikispeedia.degree(node) >= 1000])\n",
    "print(\"Nodes with more than 500 edges: \", [node for node in wikispeedia.nodes if wikispeedia.degree(node) >= 500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that biggest hubs are mainly countries. The 'United Kingdom', 'France', 'United States', and 'Europe' have over 1000 links. Since there are 4592 nodes, these nodes have link to almost 1/4 of the dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many nodes have more than 20 links? How many have only 1 link?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of nodes with degree 1\n",
    "nodes_degree_1 = [node for node in wikispeedia.nodes if wikispeedia.degree(node) == 1]\n",
    "print('Nodes with degree 1: ', nodes_degree_1)\n",
    "\n",
    "# Get the percentages\n",
    "total_nodes = len(wikispeedia.nodes)\n",
    "percentage_degree_1 = (len(nodes_degree_1) / total_nodes)\n",
    "print('% of nodes that have only 1 edge/link:', percentage_degree_1)\n",
    "\n",
    "# Count number of nodes with degree <= 20\n",
    "nodes_degree_20 = sum(1 for degree in degrees.values() if degree <= 20)\n",
    "print('% of nodes that have 20 or less edges/links:', nodes_degree_20 / total_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Average Distance between Articles\n",
    "On average, how many links/edges does it take to connect any random two articles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our graph is not strongly connected, meaning it's not possible to reach every node from every other node\n",
    "# So we can't use the built in function nx.average_shortest_path_length\n",
    "\n",
    "# This takes a long time to run (30 sec)\n",
    "shortest_paths = list(nx.all_pairs_shortest_path_length(wikispeedia))\n",
    "reachable_pairs = [(source, target, length) for source, paths in shortest_paths for target, length in paths.items() if length != float('inf')]\n",
    "total_distances = sum(length for _, _, length in reachable_pairs)\n",
    "average_distance = total_distances / len(reachable_pairs) if reachable_pairs else 0\n",
    "print(f\"Average distance between reachable nodes: {average_distance:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Games per Time\n",
    "Histogram of the number of games at each point in time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamps to datetime objects\n",
    "timestamps = paths_finished['timestamp']\n",
    "date_times = [datetime.utcfromtimestamp(ts) for ts in timestamps]\n",
    "\n",
    "# Create a histogram of timestamps\n",
    "plt.hist(date_times, bins=20, color='skyblue')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Timestamps')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of games were played in Q3 2009! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_2009_times = [dt for dt in date_times if dt.year == 2009 and dt.month in [7, 8, 9]]\n",
    "percent_q3_2009_times = len(q3_2009_times) / len(date_times)\n",
    "print(f\"Percent of finished games completed in Q3 2009: {percent_q3_2009_times:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
