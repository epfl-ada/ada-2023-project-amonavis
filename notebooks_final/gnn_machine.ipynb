{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# GNN Model\n",
    "Original A* model takes too damn long to run. We are building a GNN to make up for it.\n",
    "\n",
    "The gist of how this one works is that it does a classification model to predict the likelihood of a node being part of the solution, as in normal classification. During actual prediction, it takes a moment to only add an element if it is valid in the current answer, IE it is connected to the existing nodes."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa510e1e01a5371c"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "import data_readers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "import math\n",
    "\n",
    "# networkx\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "\n",
    "# For semantic similarity\n",
    "from urllib.parse import unquote\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "# Python functions in .py file to read data\n",
    "import machine_searchers\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "from tqdm import TqdmWarning\n",
    "warnings.filterwarnings('ignore', category=TqdmWarning)\n",
    "# I'll ignore the data embeddings, as that is "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T08:48:54.273044200Z",
     "start_time": "2023-12-15T08:48:42.268227900Z"
    }
   },
   "id": "599c835735754e7"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "wikispeedia= nx.read_edgelist('../datasets/wikispeedia_paths-and-graph/links.tsv',\n",
    "                              create_using=nx.DiGraph)\n",
    "\n",
    "def decode_word(word):\n",
    "    word = word.replace('_', ' ')\n",
    "    return unquote(word)\n",
    "\n",
    "# Create a new graph with decoded node labels\n",
    "decoded_wikispeedia = nx.DiGraph()\n",
    "\n",
    "for node in wikispeedia.nodes():\n",
    "    decoded_node = decode_word(node)\n",
    "    decoded_wikispeedia.add_node(decoded_node)\n",
    "\n",
    "# Copy the edges from the original graph to the new graph with decoded node labels\n",
    "for edge in wikispeedia.edges():\n",
    "    decoded_edge = tuple(decode_word(node) for node in edge)\n",
    "    decoded_wikispeedia.add_edge(*decoded_edge)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T08:48:55.803572300Z",
     "start_time": "2023-12-15T08:48:54.273044200Z"
    }
   },
   "id": "79c1b6d93c7fd0dc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building the embeddings\n",
    "There are a shit ton of ways of building the embeddings, for now, we will take a simpler approach of just using semantic distance. We also need to add to the embeddings if it's a source node and if it's a target node.\n",
    "\n",
    "For creating the training dataset, we also need to transform the shortest path pairs of the dataset into a vector of classifier. Which we need to test properly\n",
    "\n",
    "A decent amount of data creation..."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5f548df91ad6d20"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Getting all the embeddings\n",
    "\n",
    "We need to find the embeddings for each element. I'll just create the code and assume someone can do this better with cuda than what I feel like doing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2eb772bd121c3818"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "SentenceTransformer(\n  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n  (2): Normalize()\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do model to cuda here\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to get embeddings using sentence transformer\n",
    "def get_embedding(text):\n",
    "    temp_embed = model.encode(text, convert_to_tensor=True)\n",
    "    temp_embed = temp_embed / temp_embed.norm(p=2, dim=0, keepdim=True)\n",
    "    return temp_embed\n",
    "\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T08:48:57.546556200Z",
     "start_time": "2023-12-15T08:48:55.792780200Z"
    }
   },
   "id": "f37d201e1cb3f97b"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([384])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = model.encode('Test', convert_to_tensor=True)\n",
    "temp.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T08:50:07.843351800Z",
     "start_time": "2023-12-15T08:50:07.651958800Z"
    }
   },
   "id": "fb6e8873e3b0a4d1"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m i \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m node \u001B[38;5;129;01min\u001B[39;00m node_list:\n\u001B[1;32m----> 8\u001B[0m     text_embeddings[i] \u001B[38;5;241m=\u001B[39m get_embedding(node)\n\u001B[0;32m      9\u001B[0m     i \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "Cell \u001B[1;32mIn[3], line 5\u001B[0m, in \u001B[0;36mget_embedding\u001B[1;34m(text)\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_embedding\u001B[39m(text):\n\u001B[1;32m----> 5\u001B[0m     temp_embed \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mencode(text, convert_to_tensor\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      6\u001B[0m     temp_embed \u001B[38;5;241m=\u001B[39m temp_embed \u001B[38;5;241m/\u001B[39m temp_embed\u001B[38;5;241m.\u001B[39mnorm(p\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, keepdim\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\u001B[38;5;241m.\u001B[39mencode(text, convert_to_tensor\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:165\u001B[0m, in \u001B[0;36mSentenceTransformer.encode\u001B[1;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001B[0m\n\u001B[0;32m    162\u001B[0m features \u001B[38;5;241m=\u001B[39m batch_to_device(features, device)\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 165\u001B[0m     out_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(features)\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m output_value \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_embeddings\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    168\u001B[0m         embeddings \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    213\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    214\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 215\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\models\\Pooling.py:85\u001B[0m, in \u001B[0;36mPooling.forward\u001B[1;34m(self, features)\u001B[0m\n\u001B[0;32m     83\u001B[0m     output_vectors\u001B[38;5;241m.\u001B[39mappend(max_over_time)\n\u001B[0;32m     84\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooling_mode_mean_tokens \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooling_mode_mean_sqrt_len_tokens:\n\u001B[1;32m---> 85\u001B[0m     input_mask_expanded \u001B[38;5;241m=\u001B[39m attention_mask\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mexpand(token_embeddings\u001B[38;5;241m.\u001B[39msize())\u001B[38;5;241m.\u001B[39mfloat()\n\u001B[0;32m     86\u001B[0m     sum_embeddings \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(token_embeddings \u001B[38;5;241m*\u001B[39m input_mask_expanded, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;66;03m#If tokens are weighted (by WordWeights layer), feature 'token_weights_sum' will be present\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Didn't run this part, but we just need to run it to be free\n",
    "node_list = decoded_wikispeedia.nodes()\n",
    "\n",
    "text_embeddings = torch.zeros((len(node_list), 384))\n",
    "\n",
    "i = 0\n",
    "for node in node_list:\n",
    "    text_embeddings[i] = get_embedding(node)\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T08:56:30.965047200Z",
     "start_time": "2023-12-15T08:56:28.508150500Z"
    }
   },
   "id": "1aebd067034d33f7"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "torch.save(text_embeddings, 'text_embeddings.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T08:56:34.376668600Z",
     "start_time": "2023-12-15T08:56:34.366574100Z"
    }
   },
   "id": "434e83fc236d2666"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Getting the classification task\n",
    "\n",
    "For this, we run all shortest distance pairs to get the target classification module.\n",
    "\n",
    "We then transform this into a 2D tensor, with the following information:\n",
    "- First dimension is what is the source, and what is the target node. Everything else is 0\n",
    "- Second dimension has a 1 for all the nodes included in the shortest path. Including source and target\n",
    "\n",
    "Reason it's a 2D module is so we can extract the first one and add it to the embeddings, and the second is the actual target classification. It's just a way of guaranteeing all the units are together\n",
    "\n",
    "Also means the output will be a dictionary? I don't know if dictionary or a 3D tensor is better...\n",
    "\n",
    "I'll go with a dictionary because I don't feel like thinking. We can just pickle it or something"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "140b82168a07702e"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "all_shortest_paths = dict(nx.all_pairs_shortest_path(decoded_wikispeedia))\n",
    "shortest_paths_df = pd.DataFrame(all_shortest_paths)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T09:03:14.263455400Z",
     "start_time": "2023-12-15T09:00:17.460002200Z"
    }
   },
   "id": "abaaa78a24454db4"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "                                    Áedán mac Gabráin  \\\nÁedán mac Gabráin                 [Áedán mac Gabráin]   \nBede                        [Áedán mac Gabráin, Bede]   \nColumba                  [Áedán mac Gabráin, Columba]   \nDál Riata              [Áedán mac Gabráin, Dál Riata]   \nGreat Britain      [Áedán mac Gabráin, Great Britain]   \n\n                                                                Bede  \\\nÁedán mac Gabráin                                                NaN   \nBede                                                          [Bede]   \nColumba                [Bede, Abbot, Christian monasticism, Columba]   \nDál Riata          [Bede, Durham Cathedral, Oswald of Northumbria...   \nGreat Britain                                  [Bede, Great Britain]   \n\n                                               Columba  \\\nÁedán mac Gabráin                                  NaN   \nBede                        [Columba, Dál Riata, Bede]   \nColumba                                      [Columba]   \nDál Riata                         [Columba, Dál Riata]   \nGreat Britain      [Columba, Dál Riata, Great Britain]   \n\n                                    Dál Riata  \\\nÁedán mac Gabráin                         NaN   \nBede                        [Dál Riata, Bede]   \nColumba                  [Dál Riata, Columba]   \nDál Riata                         [Dál Riata]   \nGreat Britain      [Dál Riata, Great Britain]   \n\n                                                       Great Britain  \\\nÁedán mac Gabráin                                                NaN   \nBede               [Great Britain, British Isles (terminology), B...   \nColumba                              [Great Britain, Picts, Columba]   \nDál Riata                  [Great Britain, British Isles, Dál Riata]   \nGreat Britain                                        [Great Britain]   \n\n                                               Ireland  \\\nÁedán mac Gabráin                                  NaN   \nBede                      [Ireland, Anno Domini, Bede]   \nColumba              [Ireland, Book of Kells, Columba]   \nDál Riata          [Ireland, British Isles, Dál Riata]   \nGreat Britain                 [Ireland, Great Britain]   \n\n                                                   Isle of Man  \\\nÁedán mac Gabráin                                          NaN   \nBede                              [Isle of Man, England, Bede]   \nColumba                       [Isle of Man, Scotland, Columba]   \nDál Riata              [Isle of Man, British Isles, Dál Riata]   \nGreat Britain      [Isle of Man, British Isles, Great Britain]   \n\n                                                  Monarchy  \\\nÁedán mac Gabráin                                      NaN   \nBede                             [Monarchy, England, Bede]   \nColumba                      [Monarchy, Scotland, Columba]   \nDál Riata          [Monarchy, British monarchy, Dál Riata]   \nGreat Britain          [Monarchy, Anguilla, Great Britain]   \n\n                                               Orkney  \\\nÁedán mac Gabráin                                 NaN   \nBede                        [Orkney, Dál Riata, Bede]   \nColumba                  [Orkney, Dál Riata, Columba]   \nDál Riata                         [Orkney, Dál Riata]   \nGreat Britain      [Orkney, Dál Riata, Great Britain]   \n\n                                              Picts  ...  \\\nÁedán mac Gabráin                               NaN  ...   \nBede                                  [Picts, Bede]  ...   \nColumba                            [Picts, Columba]  ...   \nDál Riata                        [Picts, Dál Riata]  ...   \nGreat Britain      [Picts, Aberdeen, Great Britain]  ...   \n\n                                                   Wyndham Robertson  \\\nÁedán mac Gabráin                                                NaN   \nBede               [Wyndham Robertson, American Civil War, Jesus,...   \nColumba            [Wyndham Robertson, Abraham Lincoln, Charles D...   \nDál Riata          [Wyndham Robertson, U.S. state, British Isles,...   \nGreat Britain      [Wyndham Robertson, Abraham Lincoln, Andrew Jo...   \n\n                                               X-Men  The Last Stand  \\\nÁedán mac Gabráin                                                NaN   \nBede               [X-Men  The Last Stand, Vancouver, England, Bede]   \nColumba            [X-Men  The Last Stand, Canada, Irish people, ...   \nDál Riata          [X-Men  The Last Stand, Canada, Irish people, ...   \nGreat Britain      [X-Men  The Last Stand, Canada, Afghanistan, G...   \n\n                          X Window System protocols and architecture  \\\nÁedán mac Gabráin                                                NaN   \nBede               [X Window System protocols and architecture, A...   \nColumba            [X Window System protocols and architecture, A...   \nDál Riata          [X Window System protocols and architecture, A...   \nGreat Britain      [X Window System protocols and architecture, A...   \n\n                                              X Window core protocol  \\\nÁedán mac Gabráin                                                NaN   \nBede               [X Window core protocol, Unix, AT&T, United Ki...   \nColumba            [X Window core protocol, Unix, AT&T, United Ki...   \nDál Riata          [X Window core protocol, Unix, AT&T, United Ki...   \nGreat Britain      [X Window core protocol, Unix, Latin, Great Br...   \n\n                                                       Xanadu House  \\\nÁedán mac Gabráin                                               NaN   \nBede                        [Xanadu House, Business, England, Bede]   \nColumba              [Xanadu House, Florida, Irish people, Columba]   \nDál Riata          [Xanadu House, Florida, Irish people, Dál Riata]   \nGreat Britain               [Xanadu House, Computer, Great Britain]   \n\n                                                        Yellowhammer  \\\nÁedán mac Gabráin                                                NaN   \nBede                   [Yellowhammer, Bird migration, England, Bede]   \nColumba                 [Yellowhammer, Europe, Anglicanism, Columba]   \nDál Riata          [Yellowhammer, Carolus Linnaeus, Orkney, Dál R...   \nGreat Britain           [Yellowhammer, Animal, Latin, Great Britain]   \n\n                                                      Yotsuya Kaidan  \\\nÁedán mac Gabráin                                                NaN   \nBede                          [Yotsuya Kaidan, Tokyo, England, Bede]   \nColumba                   [Yotsuya Kaidan, Tokyo, Scotland, Columba]   \nDál Riata          [Yotsuya Kaidan, Osaka, Tree, British Isles, D...   \nGreat Britain       [Yotsuya Kaidan, Osaka, Aquarium, Great Britain]   \n\n                                                You're Still the One  \\\nÁedán mac Gabráin                                                NaN   \nBede               [You're Still the One, California, Bird migrat...   \nColumba            [You're Still the One, California, English lan...   \nDál Riata          [You're Still the One, California, English lan...   \nGreat Britain      [You're Still the One, California, Computer, G...   \n\n                                                        Yungay, Peru  \\\nÁedán mac Gabráin                                                NaN   \nBede                         [Yungay, Peru, Peru, 8th century, Bede]   \nColumba            [Yungay, Peru, Earthquake, Netherlands, Scotla...   \nDál Riata          [Yungay, Peru, Earthquake, United Kingdom, Bri...   \nGreat Britain      [Yungay, Peru, Earthquake, Indonesia, Great Br...   \n\n                                                       Zara Yaqob  \nÁedán mac Gabráin                                             NaN  \nBede                          [Zara Yaqob, Ethiopia, Jesus, Bede]  \nColumba              [Zara Yaqob, Ethiopia, 6th century, Columba]  \nDál Riata          [Zara Yaqob, Europe, British Isles, Dál Riata]  \nGreat Britain                  [Zara Yaqob, Islam, Great Britain]  \n\n[5 rows x 4592 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Áedán mac Gabráin</th>\n      <th>Bede</th>\n      <th>Columba</th>\n      <th>Dál Riata</th>\n      <th>Great Britain</th>\n      <th>Ireland</th>\n      <th>Isle of Man</th>\n      <th>Monarchy</th>\n      <th>Orkney</th>\n      <th>Picts</th>\n      <th>...</th>\n      <th>Wyndham Robertson</th>\n      <th>X-Men  The Last Stand</th>\n      <th>X Window System protocols and architecture</th>\n      <th>X Window core protocol</th>\n      <th>Xanadu House</th>\n      <th>Yellowhammer</th>\n      <th>Yotsuya Kaidan</th>\n      <th>You're Still the One</th>\n      <th>Yungay, Peru</th>\n      <th>Zara Yaqob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Áedán mac Gabráin</th>\n      <td>[Áedán mac Gabráin]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Bede</th>\n      <td>[Áedán mac Gabráin, Bede]</td>\n      <td>[Bede]</td>\n      <td>[Columba, Dál Riata, Bede]</td>\n      <td>[Dál Riata, Bede]</td>\n      <td>[Great Britain, British Isles (terminology), B...</td>\n      <td>[Ireland, Anno Domini, Bede]</td>\n      <td>[Isle of Man, England, Bede]</td>\n      <td>[Monarchy, England, Bede]</td>\n      <td>[Orkney, Dál Riata, Bede]</td>\n      <td>[Picts, Bede]</td>\n      <td>...</td>\n      <td>[Wyndham Robertson, American Civil War, Jesus,...</td>\n      <td>[X-Men  The Last Stand, Vancouver, England, Bede]</td>\n      <td>[X Window System protocols and architecture, A...</td>\n      <td>[X Window core protocol, Unix, AT&amp;T, United Ki...</td>\n      <td>[Xanadu House, Business, England, Bede]</td>\n      <td>[Yellowhammer, Bird migration, England, Bede]</td>\n      <td>[Yotsuya Kaidan, Tokyo, England, Bede]</td>\n      <td>[You're Still the One, California, Bird migrat...</td>\n      <td>[Yungay, Peru, Peru, 8th century, Bede]</td>\n      <td>[Zara Yaqob, Ethiopia, Jesus, Bede]</td>\n    </tr>\n    <tr>\n      <th>Columba</th>\n      <td>[Áedán mac Gabráin, Columba]</td>\n      <td>[Bede, Abbot, Christian monasticism, Columba]</td>\n      <td>[Columba]</td>\n      <td>[Dál Riata, Columba]</td>\n      <td>[Great Britain, Picts, Columba]</td>\n      <td>[Ireland, Book of Kells, Columba]</td>\n      <td>[Isle of Man, Scotland, Columba]</td>\n      <td>[Monarchy, Scotland, Columba]</td>\n      <td>[Orkney, Dál Riata, Columba]</td>\n      <td>[Picts, Columba]</td>\n      <td>...</td>\n      <td>[Wyndham Robertson, Abraham Lincoln, Charles D...</td>\n      <td>[X-Men  The Last Stand, Canada, Irish people, ...</td>\n      <td>[X Window System protocols and architecture, A...</td>\n      <td>[X Window core protocol, Unix, AT&amp;T, United Ki...</td>\n      <td>[Xanadu House, Florida, Irish people, Columba]</td>\n      <td>[Yellowhammer, Europe, Anglicanism, Columba]</td>\n      <td>[Yotsuya Kaidan, Tokyo, Scotland, Columba]</td>\n      <td>[You're Still the One, California, English lan...</td>\n      <td>[Yungay, Peru, Earthquake, Netherlands, Scotla...</td>\n      <td>[Zara Yaqob, Ethiopia, 6th century, Columba]</td>\n    </tr>\n    <tr>\n      <th>Dál Riata</th>\n      <td>[Áedán mac Gabráin, Dál Riata]</td>\n      <td>[Bede, Durham Cathedral, Oswald of Northumbria...</td>\n      <td>[Columba, Dál Riata]</td>\n      <td>[Dál Riata]</td>\n      <td>[Great Britain, British Isles, Dál Riata]</td>\n      <td>[Ireland, British Isles, Dál Riata]</td>\n      <td>[Isle of Man, British Isles, Dál Riata]</td>\n      <td>[Monarchy, British monarchy, Dál Riata]</td>\n      <td>[Orkney, Dál Riata]</td>\n      <td>[Picts, Dál Riata]</td>\n      <td>...</td>\n      <td>[Wyndham Robertson, U.S. state, British Isles,...</td>\n      <td>[X-Men  The Last Stand, Canada, Irish people, ...</td>\n      <td>[X Window System protocols and architecture, A...</td>\n      <td>[X Window core protocol, Unix, AT&amp;T, United Ki...</td>\n      <td>[Xanadu House, Florida, Irish people, Dál Riata]</td>\n      <td>[Yellowhammer, Carolus Linnaeus, Orkney, Dál R...</td>\n      <td>[Yotsuya Kaidan, Osaka, Tree, British Isles, D...</td>\n      <td>[You're Still the One, California, English lan...</td>\n      <td>[Yungay, Peru, Earthquake, United Kingdom, Bri...</td>\n      <td>[Zara Yaqob, Europe, British Isles, Dál Riata]</td>\n    </tr>\n    <tr>\n      <th>Great Britain</th>\n      <td>[Áedán mac Gabráin, Great Britain]</td>\n      <td>[Bede, Great Britain]</td>\n      <td>[Columba, Dál Riata, Great Britain]</td>\n      <td>[Dál Riata, Great Britain]</td>\n      <td>[Great Britain]</td>\n      <td>[Ireland, Great Britain]</td>\n      <td>[Isle of Man, British Isles, Great Britain]</td>\n      <td>[Monarchy, Anguilla, Great Britain]</td>\n      <td>[Orkney, Dál Riata, Great Britain]</td>\n      <td>[Picts, Aberdeen, Great Britain]</td>\n      <td>...</td>\n      <td>[Wyndham Robertson, Abraham Lincoln, Andrew Jo...</td>\n      <td>[X-Men  The Last Stand, Canada, Afghanistan, G...</td>\n      <td>[X Window System protocols and architecture, A...</td>\n      <td>[X Window core protocol, Unix, Latin, Great Br...</td>\n      <td>[Xanadu House, Computer, Great Britain]</td>\n      <td>[Yellowhammer, Animal, Latin, Great Britain]</td>\n      <td>[Yotsuya Kaidan, Osaka, Aquarium, Great Britain]</td>\n      <td>[You're Still the One, California, Computer, G...</td>\n      <td>[Yungay, Peru, Earthquake, Indonesia, Great Br...</td>\n      <td>[Zara Yaqob, Islam, Great Britain]</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 4592 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortest_paths_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T09:04:05.346238300Z",
     "start_time": "2023-12-15T09:04:05.272050400Z"
    }
   },
   "id": "530e4f56aeceba5a"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "0    Áedán mac Gabráin\n1                 Bede\n2              Columba\n3            Dál Riata\n4        Great Britain\ndtype: object"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_of_elements = pd.Series(shortest_paths_df.index)\n",
    "series_of_elements.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T09:18:25.171553800Z",
     "start_time": "2023-12-15T09:18:25.121783300Z"
    }
   },
   "id": "e52ab24515e93b0b"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[71], line 19\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m source \u001B[38;5;129;01min\u001B[39;00m node_list:\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m target \u001B[38;5;129;01min\u001B[39;00m node_list:\n\u001B[1;32m---> 19\u001B[0m         source_and_target \u001B[38;5;241m=\u001B[39m series_of_elements\u001B[38;5;241m.\u001B[39misin([source, target])\n\u001B[0;32m     20\u001B[0m         \u001B[38;5;66;03m# Order of target and source should make sense, it's just a consequence of how things are organized elsewhere\u001B[39;00m\n\u001B[0;32m     21\u001B[0m         \n\u001B[0;32m     22\u001B[0m         \u001B[38;5;66;03m# There are cases where the element is a nan, which is why we do this extra check\u001B[39;00m\n\u001B[0;32m     23\u001B[0m         \u001B[38;5;66;03m# This just skips the element, as there is no need to classify it then!\u001B[39;00m\n\u001B[0;32m     24\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(shortest_paths_df\u001B[38;5;241m.\u001B[39mloc[target, source]) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlist\u001B[39m:\n\u001B[0;32m     25\u001B[0m             \u001B[38;5;66;03m#print('No path between', source, target)\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:5564\u001B[0m, in \u001B[0;36mSeries.isin\u001B[1;34m(self, values)\u001B[0m\n\u001B[0;32m   5491\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   5492\u001B[0m \u001B[38;5;124;03mWhether elements in Series are contained in `values`.\u001B[39;00m\n\u001B[0;32m   5493\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   5561\u001B[0m \u001B[38;5;124;03mdtype: bool\u001B[39;00m\n\u001B[0;32m   5562\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   5563\u001B[0m result \u001B[38;5;241m=\u001B[39m algorithms\u001B[38;5;241m.\u001B[39misin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values, values)\n\u001B[1;32m-> 5564\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor(result, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex)\u001B[38;5;241m.\u001B[39m__finalize__(\n\u001B[0;32m   5565\u001B[0m     \u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124misin\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   5566\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:546\u001B[0m, in \u001B[0;36mSeries._constructor\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    542\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m s\u001B[38;5;241m.\u001B[39m_mgr, s\u001B[38;5;241m.\u001B[39mindex\n\u001B[0;32m    544\u001B[0m \u001B[38;5;66;03m# ----------------------------------------------------------------------\u001B[39;00m\n\u001B[1;32m--> 546\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[0;32m    547\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_constructor\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Callable[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, Series]:\n\u001B[0;32m    548\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Series\n\u001B[0;32m    550\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[0;32m    551\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_constructor_expanddim\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Callable[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, DataFrame]:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# In the resulting DF the column is the source node\n",
    "# The target is the row\n",
    "\n",
    "# There's probably a pandas way of doing this that is nicer and not a bunch of shitty for loops\n",
    "# But that's okay\n",
    "shortest_paths_classification_dict = {}\n",
    "\n",
    "# I need a way of transforming an input into the classification part...\n",
    "# Having a pandas series with the values being the node names seems like the easiest solution!\n",
    "series_of_elements = pd.Series(shortest_paths_df.index)\n",
    "\n",
    "# IMPORTANT: This means the resulting nodes are in whatever is the current order\n",
    "# This can be shit, as the system might learn other stuff by coincidence...\n",
    "# Might also not matter?\n",
    "# We need a way of guaranteeing this order is kept!!!\n",
    "\n",
    "for source in node_list:\n",
    "    for target in node_list:\n",
    "        source_and_target = series_of_elements.isin([source, target])\n",
    "        # Order of target and source should make sense, it's just a consequence of how things are organized elsewhere\n",
    "        \n",
    "        # There are cases where the element is a nan, which is why we do this extra check\n",
    "        # This just skips the element, as there is no need to classify it then!\n",
    "        if type(shortest_paths_df.loc[target, source]) != list:\n",
    "            #print('No path between', source, target)\n",
    "            continue\n",
    "        shortest_path_here = series_of_elements.isin(shortest_paths_df.loc[target, source])\n",
    "        \n",
    "        # So each element in the dict is a tuple where the first element is the classification,\n",
    "        # The second is the solution\n",
    "        shortest_paths_classification_dict[(source, target)] = (\n",
    "            torch.tensor(source_and_target, dtype=torch.float32),\n",
    "            torch.tensor(shortest_path_here, dtype=torch.float32)\n",
    "        )\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T14:07:36.729908700Z",
     "start_time": "2023-12-15T14:07:22.764199900Z"
    }
   },
   "id": "15a6acd2f145d820"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# At this point you should pickle the shortest_paths_classification_dict\n",
    "# this is to guarantee it works out!\n",
    "# Didn't write the code, but it's not ultra hard\n",
    "import pickle\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0aacdd833113206"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n        [1., 1., 0.,  ..., 0., 0., 0.]])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = shortest_paths_classification_dict[('Áedán mac Gabráin',\n",
    "                                    'German language')]\n",
    "\n",
    "temp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T12:04:07.315546800Z",
     "start_time": "2023-12-15T12:04:07.311656700Z"
    }
   },
   "id": "444960a93908c8ef"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Someone please double check that the orders line up!\n",
    "adj_matrix = nx.adjacency_matrix(decoded_wikispeedia, nodelist=node_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T12:15:57.256367700Z",
     "start_time": "2023-12-15T12:15:57.238715Z"
    }
   },
   "id": "ac63754c85faa201"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building the problem generator\n",
    "All the parts are there, now is the part of kinda building the things together.\n",
    "\n",
    "Namely, this does the following:\n",
    "- Go over the shortest_paths_classification_dict and add the relevant source/target and the y value where needed\n",
    "- Checks the queries and only supplies problems that have not been done by humans. This is to make the testing more equal to avoid issues of dataleakage\n",
    "\n",
    "There is some extra smoothing that needs to be done here, particularly because there is already a dataloader class in pytorch and in pytorch geometric. But no fucking clue how to grab it!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d12993c615b18379"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# TODO: We really should store this article_combinations as a df... it's pretty important\n",
    "#   and calculating it all the time is a pain\n",
    "\n",
    "finished_paths = pd.read_csv('../datasets/wikispeedia_paths-and-graph/paths_finished.tsv', sep='\\t', skiprows=15,\n",
    "                             names=['hashedIpAddress', 'timestamp', \"durationInSec\", 'path', \"rating\"])\n",
    "finished_paths['first_article'] = finished_paths['path'].apply(lambda x: x.split(';')[0])\n",
    "finished_paths['last_article'] = finished_paths['path'].apply(lambda x: x.split(';')[-1])\n",
    "finished_paths['path_length'] = finished_paths['path'].apply(lambda x: len(x.split(';')))\n",
    "finished_paths['date'] = pd.to_datetime(finished_paths['timestamp'], unit='s')\n",
    "\n",
    "# How many each pair of articles has been visited\n",
    "article_combinations_count = finished_paths.groupby(['first_article', 'last_article']).size().reset_index(name='count')\n",
    "\n",
    "# The mean and std of the path length for each pair of articles\n",
    "article_combinations_stats = finished_paths.groupby(['first_article', 'last_article'])['path_length'].agg(['mean', 'std']).reset_index()\n",
    "article_combinations_stats['std'] = article_combinations_stats['std'].fillna(0)\n",
    "article_combinations_stats.rename(columns={'mean': 'mean_length', 'std': 'std_length'}, inplace=True)\n",
    "\n",
    "# The mean and std of the rating for each pair of articles. \n",
    "# Note that mean and std may be nan if there are nan ratings. We purposely leave them as nan, as we don't want to fill them with 0s or 1s.\n",
    "# Depending on the application, we could change this in the future if neeeded.\n",
    "rating_combinations_stats_rating = finished_paths.groupby(['first_article', 'last_article'])['rating'].agg(['mean', 'std']).reset_index()\n",
    "#rating_combinations_stats_rating['std'] = rating_combinations_stats_rating['std'].fillna(0)\n",
    "mask = rating_combinations_stats_rating['mean'].notnull()\n",
    "rating_combinations_stats_rating.loc[mask, 'std'] = rating_combinations_stats_rating.loc[mask, 'std'].fillna(0)\n",
    "rating_combinations_stats_rating.rename(columns={'mean': 'mean_rating', 'std': 'std_rating'}, inplace=True)\n",
    "\n",
    "# The mean and std of the time for each pair of articles.\n",
    "rating_combinations_stats_time = finished_paths.groupby(['first_article', 'last_article'])['durationInSec'].agg(['mean', 'std']).reset_index()\n",
    "rating_combinations_stats_time['std'] = rating_combinations_stats_time['std'].fillna(0)\n",
    "rating_combinations_stats_time.rename(columns={'mean': 'mean_durationInSec', 'std': 'std_durationInSec'}, inplace=True)\n",
    "\n",
    "# Merging all the dataframes\n",
    "article_combinations = pd.merge(article_combinations_count, article_combinations_stats, on=['first_article', 'last_article'])\n",
    "article_combinations = pd.merge(article_combinations, rating_combinations_stats_rating, on=['first_article', 'last_article'])\n",
    "article_combinations = pd.merge(article_combinations, rating_combinations_stats_time, on=['first_article', 'last_article'])\n",
    "\n",
    "article_combinations['first_article'] = article_combinations['first_article'].apply(decode_word)\n",
    "article_combinations['last_article'] = article_combinations['last_article'].apply(decode_word)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T12:39:50.395189900Z",
     "start_time": "2023-12-15T12:39:50.120135300Z"
    }
   },
   "id": "9ce45270040a3726"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "            first_article          last_article  count  mean_length  \\\n0  €2 commemorative coins             Irish Sea      1          3.0   \n1            10th century          11th century      3          2.0   \n2            10th century              Banknote      1          5.0   \n3            10th century               Country      1          3.0   \n4            10th century  Harlem Globetrotters      2          4.5   \n\n   std_length  mean_rating  std_rating  mean_durationInSec  std_durationInSec  \n0    0.000000     1.000000    0.000000           15.000000           0.000000  \n1    0.000000     2.333333    2.309401            4.333333           1.527525  \n2    0.000000     3.000000    0.000000           48.000000           0.000000  \n3    0.000000     1.000000    0.000000           15.000000           0.000000  \n4    0.707107     2.000000    0.000000           75.000000          24.041631  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>first_article</th>\n      <th>last_article</th>\n      <th>count</th>\n      <th>mean_length</th>\n      <th>std_length</th>\n      <th>mean_rating</th>\n      <th>std_rating</th>\n      <th>mean_durationInSec</th>\n      <th>std_durationInSec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>€2 commemorative coins</td>\n      <td>Irish Sea</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>15.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10th century</td>\n      <td>11th century</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>0.000000</td>\n      <td>2.333333</td>\n      <td>2.309401</td>\n      <td>4.333333</td>\n      <td>1.527525</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10th century</td>\n      <td>Banknote</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>48.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10th century</td>\n      <td>Country</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>15.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10th century</td>\n      <td>Harlem Globetrotters</td>\n      <td>2</td>\n      <td>4.5</td>\n      <td>0.707107</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>75.000000</td>\n      <td>24.041631</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_combinations.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T12:39:51.437064100Z",
     "start_time": "2023-12-15T12:39:51.416884200Z"
    }
   },
   "id": "66403b483e2eea5e"
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "#result_list = list(zip(article_combinations['first_article'], article_combinations['last_article']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T14:17:48.074226100Z",
     "start_time": "2023-12-15T14:17:48.032895500Z"
    }
   },
   "id": "4954fe8a0754c182"
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class ProblemGenerator:\n",
    "    def __init__(self, embedded_nodes: torch.tensor = None, classification_dict: dict = None,\n",
    "                 adjacency_matrix: torch.tensor = None, paths_not_to_use: pd.DataFrame = None):\n",
    "        if embedded_nodes is None:\n",
    "            # TODO: Add a way of reading in the pickled data of the tensors\n",
    "            # Remove the return, I just added it in to have some code here\n",
    "            pass\n",
    "        \n",
    "        if classification_dict is None:\n",
    "            # TODO: Pickle data here too\n",
    "            pass\n",
    "        \n",
    "        # TODO: Do the pickling thing also for the adjacency matrix and the paths not to use!\n",
    "        \n",
    "        self.embedded_nodes = embedded_nodes\n",
    "        self.classification_dict = classification_dict\n",
    "        \n",
    "        self.adjacency_matrix = adjacency_matrix\n",
    "\n",
    "        self.remove_paths_not_to_use(paths_not_to_use)\n",
    "        \n",
    "    def remove_paths_not_to_use(self, path_not_to_use: pd.DataFrame):\n",
    "        \"\"\"Method goes over the classification dict, and removes any node pairs that\n",
    "        are contained in the paths not to use df\"\"\"\n",
    "        \n",
    "        # First part is creating a list that is just the first_article and last_article\n",
    "        \n",
    "        elems_to_remove = list(zip(article_combinations['first_article'], article_combinations['last_article']))\n",
    "        for elem in elems_to_remove:\n",
    "            self.classification_dict.pop(elem, None)\n",
    "        \n",
    "    def generate_problems(self, number_of_problems_to_generate: int = 200):\n",
    "        \"\"\"Generates problems.\n",
    "        \n",
    "        Namely, this means for the number_of_problems_to_generate, pick a problem,\n",
    "        attach the source and target matrix to the embeddings, and output the y value\n",
    "        as an adjacent value\n",
    "        \n",
    "        I guess this also means the output should be 3d, so we need to do some work on\n",
    "        the shape so that it has that structure!\n",
    "        \n",
    "        I'm not sure how to include the adjacency matrix in the output though, sorry :D\"\"\"\n",
    "        \n",
    "        # This should get the random keys\n",
    "        random_keys = random.sample(sorted(self.classification_dict.keys()), number_of_problems_to_generate)\n",
    "        \n",
    "        # Now, for each key generate a version of the problem\n",
    "        # I'll store the info in a 3d tensor, which I just update at each count!\n",
    "        # It's shape[1] because we add the source and target nodes to the inputs\n",
    "        emb_nodes_shape = self.embedded_nodes.shape\n",
    "        X_values = torch.zeros((number_of_problems_to_generate, emb_nodes_shape[0], emb_nodes_shape[1] + 1))\n",
    "        \n",
    "        # This is a 2d matrix, first dim is the inputs\n",
    "        # second dim is the solutions for each of the relevant elems\n",
    "        y_values = torch.zeros((number_of_problems_to_generate, emb_nodes_shape[0]))\n",
    "        \n",
    "        i = 0\n",
    "        for elem in random_keys:\n",
    "            cur_source_and_target, cur_solution = self.classification_dict[elem]\n",
    "            y_values[i] = cur_solution\n",
    "            \n",
    "            # TODO: I'm not sure if it's worth it to copy the embedded nodes...\n",
    "            # This is to avoid weird shit from happening with the gradient\n",
    "            X_values[i] = torch.cat([self.embedded_nodes, cur_source_and_target.unsqueeze(dim=1)], dim=1)\n",
    "            \n",
    "        return X_values, y_values\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T14:14:23.400451800Z",
     "start_time": "2023-12-15T14:14:23.363623Z"
    }
   },
   "id": "2d792a297542495b"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4592, 385])\n",
      "torch.Size([5, 4592])\n"
     ]
    }
   ],
   "source": [
    "# This is to show what the structure is for the prob_gen!\n",
    "prob_gen = ProblemGenerator(text_embeddings, shortest_paths_classification_dict,\n",
    "                            adj_matrix, article_combinations)\n",
    "\n",
    "test_X, test_y = prob_gen.generate_problems(5)\n",
    "\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T14:15:32.704187100Z",
     "start_time": "2023-12-15T14:15:32.601639300Z"
    }
   },
   "id": "5d129cdfc52253dd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Okay, the previous parts work, which is good!\n",
    "\n",
    "They need to be added to separate files and we need to do some pickling, that's okay!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edef34bfe3422653"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remark:\n",
    "\n",
    "After reading part of the documentation for pytorch geometric, we need to do some extra alterations for the inputs...\n",
    "\n",
    "Namely, I think it's related to the way we give the edge index. I haven't thought about this for too much, but it's important to note\n",
    "\n",
    "This should give an example of what to do. We have to adapt it of course, but at least it's an important part of\n",
    "what we need:\n",
    "https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2824ef9113fbe289"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The actual GNN\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0ae5aa919bcf596"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
