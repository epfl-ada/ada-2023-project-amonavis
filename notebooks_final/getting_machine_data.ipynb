{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f521180547c8733",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Why?\n",
    "Idea of this notebook is to give the template that will be run on how to get all of the machine data.\n",
    "\n",
    "Namely, finding the paths and explorations that the two models take. \n",
    "Ideally it'll be upgraded to work with different models too, but that's for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e5d6d9e704dcf5c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T18:25:07.465435500Z",
     "start_time": "2023-12-08T18:25:03.315301300Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "import data_readers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "import math\n",
    "\n",
    "# networkx\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "\n",
    "# For semantic similarity\n",
    "from urllib.parse import unquote\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "# Python functions in .py file to read data\n",
    "import machine_searchers\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "from tqdm import TqdmWarning\n",
    "warnings.filterwarnings('ignore', category=TqdmWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c52d6a923bfe0dcb",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T18:25:07.612854100Z",
     "start_time": "2023-12-08T18:25:07.469442500Z"
    }
   },
   "outputs": [],
   "source": [
    "finished_paths = pd.read_csv('../datasets/wikispeedia_paths-and-graph/paths_finished.tsv', sep='\\t', skiprows=15,\n",
    "                                 names=['hashedIpAddress', 'timestamp', \"durationInSec\", 'path', \"rating\"])\n",
    "finished_paths['first_article'] = finished_paths['path'].apply(lambda x: x.split(';')[0])\n",
    "finished_paths['last_article'] = finished_paths['path'].apply(lambda x: x.split(';')[-1])\n",
    "finished_paths['path_length'] = finished_paths['path'].apply(lambda x: len(x.split(';')))\n",
    "finished_paths['date'] = pd.to_datetime(finished_paths['timestamp'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b4531dd977229a8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T18:25:07.750459400Z",
     "start_time": "2023-12-08T18:25:07.615359100Z"
    }
   },
   "outputs": [],
   "source": [
    "# How many each pair of articles has been visited\n",
    "article_combinations_count = finished_paths.groupby(['first_article', 'last_article']).size().reset_index(name='count')\n",
    "\n",
    "# The mean and std of the path length for each pair of articles\n",
    "article_combinations_stats = finished_paths.groupby(['first_article', 'last_article'])['path_length'].agg(['mean', 'std']).reset_index()\n",
    "article_combinations_stats['std'] = article_combinations_stats['std'].fillna(0)\n",
    "article_combinations_stats.rename(columns={'mean': 'mean_length', 'std': 'std_length'}, inplace=True)\n",
    "\n",
    "# The mean and std of the rating for each pair of articles. \n",
    "# Note that mean and std may be nan if there are nan ratings. We purposely leave them as nan, as we don't want to fill them with 0s or 1s.\n",
    "# Depending on the application, we could change this in the future if neeeded.\n",
    "rating_combinations_stats_rating = finished_paths.groupby(['first_article', 'last_article'])['rating'].agg(['mean', 'std']).reset_index()\n",
    "#rating_combinations_stats_rating['std'] = rating_combinations_stats_rating['std'].fillna(0)\n",
    "mask = rating_combinations_stats_rating['mean'].notnull()\n",
    "rating_combinations_stats_rating.loc[mask, 'std'] = rating_combinations_stats_rating.loc[mask, 'std'].fillna(0)\n",
    "rating_combinations_stats_rating.rename(columns={'mean': 'mean_rating', 'std': 'std_rating'}, inplace=True)\n",
    "\n",
    "# The mean and std of the time for each pair of articles.\n",
    "rating_combinations_stats_time = finished_paths.groupby(['first_article', 'last_article'])['durationInSec'].agg(['mean', 'std']).reset_index()\n",
    "rating_combinations_stats_time['std'] = rating_combinations_stats_time['std'].fillna(0)\n",
    "rating_combinations_stats_time.rename(columns={'mean': 'mean_durationInSec', 'std': 'std_durationInSec'}, inplace=True)\n",
    "\n",
    "# Merging all the dataframes\n",
    "article_combinations = pd.merge(article_combinations_count, article_combinations_stats, on=['first_article', 'last_article'])\n",
    "article_combinations = pd.merge(article_combinations, rating_combinations_stats_rating, on=['first_article', 'last_article'])\n",
    "article_combinations = pd.merge(article_combinations, rating_combinations_stats_time, on=['first_article', 'last_article'])\n",
    "\n",
    "# The number of unique sources and targets\n",
    "unique_sources = finished_paths['first_article'].value_counts().reset_index()\n",
    "unique_targets = finished_paths['last_article'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "341cf1f617a9831f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T18:25:08.230893600Z",
     "start_time": "2023-12-08T18:25:08.210204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                    first_article          last_article  count  mean_length  \\\n0  %E2%82%AC2_commemorative_coins             Irish_Sea      1          3.0   \n1                    10th_century          11th_century      3          2.0   \n2                    10th_century              Banknote      1          5.0   \n3                    10th_century               Country      1          3.0   \n4                    10th_century  Harlem_Globetrotters      2          4.5   \n\n   std_length  mean_rating  std_rating  mean_durationInSec  std_durationInSec  \n0    0.000000     1.000000    0.000000           15.000000           0.000000  \n1    0.000000     2.333333    2.309401            4.333333           1.527525  \n2    0.000000     3.000000    0.000000           48.000000           0.000000  \n3    0.000000     1.000000    0.000000           15.000000           0.000000  \n4    0.707107     2.000000    0.000000           75.000000          24.041631  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>first_article</th>\n      <th>last_article</th>\n      <th>count</th>\n      <th>mean_length</th>\n      <th>std_length</th>\n      <th>mean_rating</th>\n      <th>std_rating</th>\n      <th>mean_durationInSec</th>\n      <th>std_durationInSec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>%E2%82%AC2_commemorative_coins</td>\n      <td>Irish_Sea</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>15.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10th_century</td>\n      <td>11th_century</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>0.000000</td>\n      <td>2.333333</td>\n      <td>2.309401</td>\n      <td>4.333333</td>\n      <td>1.527525</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10th_century</td>\n      <td>Banknote</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>48.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10th_century</td>\n      <td>Country</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>15.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10th_century</td>\n      <td>Harlem_Globetrotters</td>\n      <td>2</td>\n      <td>4.5</td>\n      <td>0.707107</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>75.000000</td>\n      <td>24.041631</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_combinations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f71bc131",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T18:25:10.398399900Z",
     "start_time": "2023-12-08T18:25:09.893374300Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to get embeddings using sentence transformer\n",
    "def get_embedding(text):\n",
    "    return model.encode(text, convert_to_tensor=True)\n",
    "\n",
    "# Function to perform L2 normalization on the embeddings\n",
    "def l2_normalize(tensor):\n",
    "    return tensor / tensor.norm(p=2, dim=0, keepdim=True)\n",
    "\n",
    "# Function to calculate semantic similarity between two pieces of text\n",
    "def semantic_similarity(word1, word2):\n",
    "    embedding1 = get_embedding(word1)\n",
    "    embedding2 = get_embedding(word2)\n",
    "\n",
    "    # L2 normalization of the embeddings (to make sure, although embedding should already be normalized)\n",
    "    embedding1_normalized = l2_normalize(embedding1)\n",
    "    embedding2_normalized = l2_normalize(embedding2)\n",
    "\n",
    "    # Compute and return the similarity of normalized tensors\n",
    "    return torch.dot(embedding1_normalized, embedding2_normalized).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33593d5dce82fe85",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T18:25:13.317806100Z",
     "start_time": "2023-12-08T18:25:12.230819900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the modded a star that returns explored nodes:\n",
      " Found solution for Actor to Japan exploring the following number of nodes: 1\n",
      " Found it in: 0.09830498695373535\n",
      "Using depth first only A star that returns explored nodes:\n",
      " Found solution for Actor to Japan exploring the following number of nodes: 1\n",
      " Found it in: 0.09151577949523926\n"
     ]
    }
   ],
   "source": [
    "wikispeedia= nx.read_edgelist('../datasets/wikispeedia_paths-and-graph/links.tsv',\n",
    "                              create_using=nx.DiGraph)\n",
    "\n",
    "def decode_word(word):\n",
    "    word = word.replace('_', ' ')\n",
    "    return unquote(word)\n",
    "\n",
    "# Create a new graph with decoded node labels\n",
    "decoded_wikispeedia = nx.DiGraph()\n",
    "\n",
    "for node in wikispeedia.nodes():\n",
    "    decoded_node = decode_word(node)\n",
    "    decoded_wikispeedia.add_node(decoded_node)\n",
    "\n",
    "# Copy the edges from the original graph to the new graph with decoded node labels\n",
    "for edge in wikispeedia.edges():\n",
    "    decoded_edge = tuple(decode_word(node) for node in edge)\n",
    "    decoded_wikispeedia.add_edge(*decoded_edge)\n",
    "\n",
    "start_time = time.time()\n",
    "lib_path_1, lib_explore_1 = machine_searchers.modded_astar_path(wikispeedia, 'Actor', 'Japan', heuristic=semantic_similarity)\n",
    "end_time = time.time()\n",
    "\n",
    "# It's len - 1 because the target node is also included, and that node wasn't explored\n",
    "print(\"Using the modded a star that returns explored nodes:\")\n",
    "print(\" Found solution for Actor to Japan exploring the following number of nodes:\", len(lib_explore_1)-1)\n",
    "print(\" Found it in:\", end_time-start_time)\n",
    "\n",
    "start_time = time.time()\n",
    "lib_path_2, lib_explore_2 = machine_searchers.only_depth_first_astar_path(wikispeedia, 'Actor', 'Japan', heuristic=semantic_similarity)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Using depth first only A star that returns explored nodes:\")\n",
    "print(\" Found solution for Actor to Japan exploring the following number of nodes:\", len(lib_explore_2)-1)\n",
    "print(\" Found it in:\", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2af62950",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T18:25:16.874182Z",
     "start_time": "2023-12-08T18:25:16.827425400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            first_article          last_article  count  mean_length  \\\n0  €2 commemorative coins             Irish Sea      1          3.0   \n1            10th century          11th century      3          2.0   \n2            10th century              Banknote      1          5.0   \n3            10th century               Country      1          3.0   \n4            10th century  Harlem Globetrotters      2          4.5   \n\n   std_length  mean_rating  std_rating  mean_durationInSec  std_durationInSec  \n0    0.000000     1.000000    0.000000           15.000000           0.000000  \n1    0.000000     2.333333    2.309401            4.333333           1.527525  \n2    0.000000     3.000000    0.000000           48.000000           0.000000  \n3    0.000000     1.000000    0.000000           15.000000           0.000000  \n4    0.707107     2.000000    0.000000           75.000000          24.041631  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>first_article</th>\n      <th>last_article</th>\n      <th>count</th>\n      <th>mean_length</th>\n      <th>std_length</th>\n      <th>mean_rating</th>\n      <th>std_rating</th>\n      <th>mean_durationInSec</th>\n      <th>std_durationInSec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>€2 commemorative coins</td>\n      <td>Irish Sea</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>15.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10th century</td>\n      <td>11th century</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>0.000000</td>\n      <td>2.333333</td>\n      <td>2.309401</td>\n      <td>4.333333</td>\n      <td>1.527525</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10th century</td>\n      <td>Banknote</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>48.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10th century</td>\n      <td>Country</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>15.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10th century</td>\n      <td>Harlem Globetrotters</td>\n      <td>2</td>\n      <td>4.5</td>\n      <td>0.707107</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>75.000000</td>\n      <td>24.041631</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_articles = article_combinations.copy()\n",
    "decoded_articles[['first_article', 'last_article']] = article_combinations[['first_article', 'last_article']].apply(lambda col: col.apply(decode_word))\n",
    "decoded_articles.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(28718, 9)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_articles.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T18:35:59.748940Z",
     "start_time": "2023-12-08T18:35:59.741878300Z"
    }
   },
   "id": "175f4c20d9574c89"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "'Banknote'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_articles['last_article'][2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T18:25:18.632109700Z",
     "start_time": "2023-12-08T18:25:18.616567500Z"
    }
   },
   "id": "dd9e8fde10522d52"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "['€2 commemorative coins', 'United Kingdom', 'Irish Sea']"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_path, temp_explore = machine_searchers.modded_astar_path(decoded_wikispeedia, decoded_articles['first_article'][0], decoded_articles['last_article'][0], heuristic=semantic_similarity)\n",
    "temp_path"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T18:25:35.760323900Z",
     "start_time": "2023-12-08T18:25:20.555222500Z"
    }
   },
   "id": "4420ea7075d5c449"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Irish Sea not reachable from €2 commemorative coins in depth first version\n"
     ]
    },
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_path, temp_explore = machine_searchers.only_depth_first_astar_path(decoded_wikispeedia, decoded_articles['first_article'][0], decoded_articles['last_article'][0], heuristic=semantic_similarity)\n",
    "temp_path"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T18:26:19.548496Z",
     "start_time": "2023-12-08T18:25:35.760323900Z"
    }
   },
   "id": "c1f2ef861737f4b9"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "['10th century', 'Scotland', 'Banknote']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_path"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T18:02:19.103678100Z",
     "start_time": "2023-12-08T18:02:19.096123900Z"
    }
   },
   "id": "42f1d41b371cf60"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def apply_machine_first(row) -> list:\n",
    "    source = row['first_article']\n",
    "    target = row['last_article']\n",
    "\n",
    "    lib_path_1, lib_explore_1 = machine_searchers.modded_astar_path(decoded_wikispeedia, source, target, heuristic=semantic_similarity)\n",
    "    #lib_path_2, lib_explore_2 = machine_searchers.only_depth_first_astar_path(decoded_wikispeedia, source, target, heuristic=semantic_similarity)\n",
    "\n",
    "    return [source, target, len(lib_explore_1)-1, lib_path_1, lib_explore_1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T18:34:53.114401Z",
     "start_time": "2023-12-08T18:34:53.101772400Z"
    }
   },
   "id": "fce6fef7bddbe481"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def apply_machine_second(row) -> list:\n",
    "    source = row['first_article']\n",
    "    target = row['last_article']\n",
    "\n",
    "    #lib_path_1, lib_explore_1 = machine_searchers.modded_astar_path(decoded_wikispeedia, source, target, heuristic=semantic_similarity)\n",
    "    lib_path_2, lib_explore_2 = machine_searchers.only_depth_first_astar_path(decoded_wikispeedia, source, target, heuristic=semantic_similarity)\n",
    "\n",
    "    return [source, target, len(lib_explore_2)-1, lib_path_2, lib_explore_2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T18:34:54.645559300Z",
     "start_time": "2023-12-08T18:34:54.618881900Z"
    }
   },
   "id": "4e667e7115253702"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished first\n",
      " Found it in: 845.3341653347015\n",
      "Node Irish Sea not reachable from €2 commemorative coins in depth first version\n",
      "Node Banknote not reachable from 10th century in depth first version\n",
      "Node Country not reachable from 10th century in depth first version\n",
      "Node Harlem Globetrotters not reachable from 10th century in depth first version\n",
      "Node History of democracy not reachable from 10th century in depth first version\n",
      "Node Marco Polo not reachable from 10th century in depth first version\n",
      "Node Dimetrodon not reachable from 11th century in depth first version\n",
      "Node Education in the United States not reachable from 11th century in depth first version\n",
      "Node Hurricane Alex (2004) not reachable from 11th century in depth first version\n",
      "Node John Adams not reachable from 11th century in depth first version\n",
      "Node Lhasa not reachable from 11th century in depth first version\n",
      "Node Plum not reachable from 11th century in depth first version\n",
      "Node Taiwan not reachable from 11th century in depth first version\n",
      "Node Warsaw not reachable from 11th century in depth first version\n",
      "Node Belfast not reachable from 12th century in depth first version\n",
      "Node Flat Earth not reachable from 12th century in depth first version\n",
      "Node Geography of Ireland not reachable from 12th century in depth first version\n"
     ]
    }
   ],
   "source": [
    "# garbage = decoded_articles[:25]\n",
    "# \n",
    "# start_time = time.time()\n",
    "# temp_df = garbage.apply(apply_machine_first, axis=1, result_type='expand')\n",
    "# end_time = time.time()\n",
    "# print(\"Finished first\")\n",
    "# print(\" Found it in:\", end_time-start_time)\n",
    "# \n",
    "# \n",
    "# temp_2_df = garbage.apply(apply_machine_second, axis=1, result_type='expand')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-08T19:04:05.866418400Z"
    }
   },
   "id": "98b6a9983086282d"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "splits = [(0, 6000), (6000, 12000), (12000, 18000), (18000, 24000), (24000, 28718)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T20:31:18.086389Z",
     "start_time": "2023-12-08T20:31:18.073183600Z"
    }
   },
   "id": "7e622c59b979dc2e"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4399e0a7f204a4e0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T20:32:01.274096300Z",
     "start_time": "2023-12-08T20:31:55.445530300Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 12\u001B[0m\n\u001B[0;32m      9\u001B[0m target \u001B[38;5;241m=\u001B[39m row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlast_article\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 12\u001B[0m     lib_path_1, lib_explore_1 \u001B[38;5;241m=\u001B[39m machine_searchers\u001B[38;5;241m.\u001B[39mmodded_astar_path(decoded_wikispeedia, source, target, heuristic\u001B[38;5;241m=\u001B[39msemantic_similarity)\n\u001B[0;32m     13\u001B[0m     lib_path_2, lib_explore_2 \u001B[38;5;241m=\u001B[39m machine_searchers\u001B[38;5;241m.\u001B[39monly_depth_first_astar_path(decoded_wikispeedia, source, target, heuristic\u001B[38;5;241m=\u001B[39msemantic_similarity)\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;66;03m# Now storing the index, to easily know what's not stored\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\ada-2023-project-amonavis\\machine_searchers.py:158\u001B[0m, in \u001B[0;36mmodded_astar_path\u001B[1;34m(G, source, target, heuristic, weight)\u001B[0m\n\u001B[0;32m    156\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 158\u001B[0m     h \u001B[38;5;241m=\u001B[39m heuristic(neighbor, target)\n\u001B[0;32m    159\u001B[0m enqueued[neighbor] \u001B[38;5;241m=\u001B[39m ncost, h\n\u001B[0;32m    160\u001B[0m push(queue, (ncost \u001B[38;5;241m+\u001B[39m h, \u001B[38;5;28mnext\u001B[39m(c), neighbor, ncost, curnode))\n",
      "Cell \u001B[1;32mIn[5], line 14\u001B[0m, in \u001B[0;36msemantic_similarity\u001B[1;34m(word1, word2)\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msemantic_similarity\u001B[39m(word1, word2):\n\u001B[0;32m     13\u001B[0m     embedding1 \u001B[38;5;241m=\u001B[39m get_embedding(word1)\n\u001B[1;32m---> 14\u001B[0m     embedding2 \u001B[38;5;241m=\u001B[39m get_embedding(word2)\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;66;03m# L2 normalization of the embeddings (to make sure, although embedding should already be normalized)\u001B[39;00m\n\u001B[0;32m     17\u001B[0m     embedding1_normalized \u001B[38;5;241m=\u001B[39m l2_normalize(embedding1)\n",
      "Cell \u001B[1;32mIn[5], line 5\u001B[0m, in \u001B[0;36mget_embedding\u001B[1;34m(text)\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_embedding\u001B[39m(text):\n\u001B[1;32m----> 5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\u001B[38;5;241m.\u001B[39mencode(text, convert_to_tensor\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:165\u001B[0m, in \u001B[0;36mSentenceTransformer.encode\u001B[1;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001B[0m\n\u001B[0;32m    162\u001B[0m features \u001B[38;5;241m=\u001B[39m batch_to_device(features, device)\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 165\u001B[0m     out_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(features)\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m output_value \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_embeddings\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    168\u001B[0m         embeddings \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    213\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    214\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 215\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:66\u001B[0m, in \u001B[0;36mTransformer.forward\u001B[1;34m(self, features)\u001B[0m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m features:\n\u001B[0;32m     64\u001B[0m     trans_features[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m features[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m---> 66\u001B[0m output_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtrans_features, return_dict\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m     67\u001B[0m output_tokens \u001B[38;5;241m=\u001B[39m output_states[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     69\u001B[0m features\u001B[38;5;241m.\u001B[39mupdate({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_embeddings\u001B[39m\u001B[38;5;124m'\u001B[39m: output_tokens, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m: features[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m]})\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1022\u001B[0m, in \u001B[0;36mBertModel.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1013\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[0;32m   1015\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(\n\u001B[0;32m   1016\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[0;32m   1017\u001B[0m     position_ids\u001B[38;5;241m=\u001B[39mposition_ids,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1020\u001B[0m     past_key_values_length\u001B[38;5;241m=\u001B[39mpast_key_values_length,\n\u001B[0;32m   1021\u001B[0m )\n\u001B[1;32m-> 1022\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(\n\u001B[0;32m   1023\u001B[0m     embedding_output,\n\u001B[0;32m   1024\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mextended_attention_mask,\n\u001B[0;32m   1025\u001B[0m     head_mask\u001B[38;5;241m=\u001B[39mhead_mask,\n\u001B[0;32m   1026\u001B[0m     encoder_hidden_states\u001B[38;5;241m=\u001B[39mencoder_hidden_states,\n\u001B[0;32m   1027\u001B[0m     encoder_attention_mask\u001B[38;5;241m=\u001B[39mencoder_extended_attention_mask,\n\u001B[0;32m   1028\u001B[0m     past_key_values\u001B[38;5;241m=\u001B[39mpast_key_values,\n\u001B[0;32m   1029\u001B[0m     use_cache\u001B[38;5;241m=\u001B[39muse_cache,\n\u001B[0;32m   1030\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[0;32m   1031\u001B[0m     output_hidden_states\u001B[38;5;241m=\u001B[39moutput_hidden_states,\n\u001B[0;32m   1032\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[0;32m   1033\u001B[0m )\n\u001B[0;32m   1034\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1035\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:612\u001B[0m, in \u001B[0;36mBertEncoder.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    603\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[0;32m    604\u001B[0m         create_custom_forward(layer_module),\n\u001B[0;32m    605\u001B[0m         hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    609\u001B[0m         encoder_attention_mask,\n\u001B[0;32m    610\u001B[0m     )\n\u001B[0;32m    611\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 612\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m layer_module(\n\u001B[0;32m    613\u001B[0m         hidden_states,\n\u001B[0;32m    614\u001B[0m         attention_mask,\n\u001B[0;32m    615\u001B[0m         layer_head_mask,\n\u001B[0;32m    616\u001B[0m         encoder_hidden_states,\n\u001B[0;32m    617\u001B[0m         encoder_attention_mask,\n\u001B[0;32m    618\u001B[0m         past_key_value,\n\u001B[0;32m    619\u001B[0m         output_attentions,\n\u001B[0;32m    620\u001B[0m     )\n\u001B[0;32m    622\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    623\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:497\u001B[0m, in \u001B[0;36mBertLayer.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    485\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    486\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    487\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    494\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[0;32m    495\u001B[0m     \u001B[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[39;00m\n\u001B[0;32m    496\u001B[0m     self_attn_past_key_value \u001B[38;5;241m=\u001B[39m past_key_value[:\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 497\u001B[0m     self_attention_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattention(\n\u001B[0;32m    498\u001B[0m         hidden_states,\n\u001B[0;32m    499\u001B[0m         attention_mask,\n\u001B[0;32m    500\u001B[0m         head_mask,\n\u001B[0;32m    501\u001B[0m         output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[0;32m    502\u001B[0m         past_key_value\u001B[38;5;241m=\u001B[39mself_attn_past_key_value,\n\u001B[0;32m    503\u001B[0m     )\n\u001B[0;32m    504\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m self_attention_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    506\u001B[0m     \u001B[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:436\u001B[0m, in \u001B[0;36mBertAttention.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    417\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    418\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    419\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    425\u001B[0m     output_attentions: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    426\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[0;32m    427\u001B[0m     self_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mself(\n\u001B[0;32m    428\u001B[0m         hidden_states,\n\u001B[0;32m    429\u001B[0m         attention_mask,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    434\u001B[0m         output_attentions,\n\u001B[0;32m    435\u001B[0m     )\n\u001B[1;32m--> 436\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput(self_outputs[\u001B[38;5;241m0\u001B[39m], hidden_states)\n\u001B[0;32m    437\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (attention_output,) \u001B[38;5;241m+\u001B[39m self_outputs[\u001B[38;5;241m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n\u001B[0;32m    438\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:386\u001B[0m, in \u001B[0;36mBertSelfOutput.forward\u001B[1;34m(self, hidden_states, input_tensor)\u001B[0m\n\u001B[0;32m    385\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor, input_tensor: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[1;32m--> 386\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdense(hidden_states)\n\u001B[0;32m    387\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(hidden_states)\n\u001B[0;32m    388\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mLayerNorm(hidden_states \u001B[38;5;241m+\u001B[39m input_tensor)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mlinear(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "result_dict = {}\n",
    "\n",
    "chosen_split = splits[0]\n",
    "\n",
    "to_process = decoded_articles[chosen_split[0]: chosen_split[1]]\n",
    "\n",
    "for index, row in to_process.iterrows():\n",
    "    source = row['first_article']\n",
    "    target = row['last_article']\n",
    "\n",
    "    try:\n",
    "        lib_path_1, lib_explore_1 = machine_searchers.modded_astar_path(decoded_wikispeedia, source, target, heuristic=semantic_similarity)\n",
    "        lib_path_2, lib_explore_2 = machine_searchers.only_depth_first_astar_path(decoded_wikispeedia, source, target, heuristic=semantic_similarity)\n",
    "\n",
    "        # Now storing the index, to easily know what's not stored\n",
    "        result_dict[index] = [index, source, target, len(lib_explore_1)-1, lib_path_1, lib_explore_1, len(lib_explore_2)-1, lib_path_2, lib_explore_2]\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle the exception (e.g., log it, assign None or np.nan, etc.)\n",
    "        result_dict[index] = [source, target, np.nan, np.nan, np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66ac1344d60b0c68",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "6 columns passed, passed data had 8 columns",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[0;32m~/Library/CloudStorage/OneDrive-epfl.ch/Fall 2023/CS-401 Applied Data Analysis (ADA)/GitHub/ada-2023-project-amonavis/amonavis/lib/python3.9/site-packages/pandas/core/internals/construction.py:939\u001B[0m, in \u001B[0;36m_finalize_columns_and_data\u001B[0;34m(content, columns, dtype)\u001B[0m\n\u001B[1;32m    938\u001B[0m \u001B[39mtry\u001B[39;00m:\n\u001B[0;32m--> 939\u001B[0m     columns \u001B[39m=\u001B[39m _validate_or_indexify_columns(contents, columns)\n\u001B[1;32m    940\u001B[0m \u001B[39mexcept\u001B[39;00m \u001B[39mAssertionError\u001B[39;00m \u001B[39mas\u001B[39;00m err:\n\u001B[1;32m    941\u001B[0m     \u001B[39m# GH#26429 do not raise user-facing AssertionError\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/CloudStorage/OneDrive-epfl.ch/Fall 2023/CS-401 Applied Data Analysis (ADA)/GitHub/ada-2023-project-amonavis/amonavis/lib/python3.9/site-packages/pandas/core/internals/construction.py:986\u001B[0m, in \u001B[0;36m_validate_or_indexify_columns\u001B[0;34m(content, columns)\u001B[0m\n\u001B[1;32m    984\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m is_mi_list \u001B[39mand\u001B[39;00m \u001B[39mlen\u001B[39m(columns) \u001B[39m!=\u001B[39m \u001B[39mlen\u001B[39m(content):  \u001B[39m# pragma: no cover\u001B[39;00m\n\u001B[1;32m    985\u001B[0m     \u001B[39m# caller's responsibility to check for this...\u001B[39;00m\n\u001B[0;32m--> 986\u001B[0m     \u001B[39mraise\u001B[39;00m \u001B[39mAssertionError\u001B[39;00m(\n\u001B[1;32m    987\u001B[0m         \u001B[39mf\u001B[39m\u001B[39m\"\u001B[39m\u001B[39m{\u001B[39;00m\u001B[39mlen\u001B[39m(columns)\u001B[39m}\u001B[39;00m\u001B[39m columns passed, passed data had \u001B[39m\u001B[39m\"\u001B[39m\n\u001B[1;32m    988\u001B[0m         \u001B[39mf\u001B[39m\u001B[39m\"\u001B[39m\u001B[39m{\u001B[39;00m\u001B[39mlen\u001B[39m(content)\u001B[39m}\u001B[39;00m\u001B[39m columns\u001B[39m\u001B[39m\"\u001B[39m\n\u001B[1;32m    989\u001B[0m     )\n\u001B[1;32m    990\u001B[0m \u001B[39mif\u001B[39;00m is_mi_list:\n\u001B[1;32m    991\u001B[0m     \u001B[39m# check if nested list column, length of each sub-list should be equal\u001B[39;00m\n",
      "\u001B[0;31mAssertionError\u001B[0m: 6 columns passed, passed data had 8 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m/Users/carloscc/Library/CloudStorage/OneDrive-epfl.ch/Fall 2023/CS-401 Applied Data Analysis (ADA)/GitHub/ada-2023-project-amonavis/notebooks_final/getting_machine_data.ipynb Cell 12\u001B[0m line \u001B[0;36m1\n\u001B[0;32m----> <a href='vscode-notebook-cell:/Users/carloscc/Library/CloudStorage/OneDrive-epfl.ch/Fall%202023/CS-401%20Applied%20Data%20Analysis%20%28ADA%29/GitHub/ada-2023-project-amonavis/notebooks_final/getting_machine_data.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001B[0m resulting_df \u001B[39m=\u001B[39m pd\u001B[39m.\u001B[39;49mDataFrame\u001B[39m.\u001B[39;49mfrom_dict(result_dict, orient\u001B[39m=\u001B[39;49m\u001B[39m'\u001B[39;49m\u001B[39mindex\u001B[39;49m\u001B[39m'\u001B[39;49m, \n\u001B[1;32m      <a href='vscode-notebook-cell:/Users/carloscc/Library/CloudStorage/OneDrive-epfl.ch/Fall%202023/CS-401%20Applied%20Data%20Analysis%20%28ADA%29/GitHub/ada-2023-project-amonavis/notebooks_final/getting_machine_data.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001B[0m                                       columns\u001B[39m=\u001B[39;49m[\u001B[39m'\u001B[39;49m\u001B[39mSource\u001B[39;49m\u001B[39m'\u001B[39;49m, \u001B[39m'\u001B[39;49m\u001B[39mTarget\u001B[39;49m\u001B[39m'\u001B[39;49m, \u001B[39m'\u001B[39;49m\u001B[39mPath_1\u001B[39;49m\u001B[39m'\u001B[39;49m, \u001B[39m'\u001B[39;49m\u001B[39mExplored_1\u001B[39;49m\u001B[39m'\u001B[39;49m, \u001B[39m'\u001B[39;49m\u001B[39mPath_2\u001B[39;49m\u001B[39m'\u001B[39;49m, \u001B[39m'\u001B[39;49m\u001B[39mExplored_2\u001B[39;49m\u001B[39m'\u001B[39;49m])\n\u001B[1;32m      <a href='vscode-notebook-cell:/Users/carloscc/Library/CloudStorage/OneDrive-epfl.ch/Fall%202023/CS-401%20Applied%20Data%20Analysis%20%28ADA%29/GitHub/ada-2023-project-amonavis/notebooks_final/getting_machine_data.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001B[0m resulting_df\n",
      "File \u001B[0;32m~/Library/CloudStorage/OneDrive-epfl.ch/Fall 2023/CS-401 Applied Data Analysis (ADA)/GitHub/ada-2023-project-amonavis/amonavis/lib/python3.9/site-packages/pandas/core/frame.py:1813\u001B[0m, in \u001B[0;36mDataFrame.from_dict\u001B[0;34m(cls, data, orient, dtype, columns)\u001B[0m\n\u001B[1;32m   1807\u001B[0m     \u001B[39mraise\u001B[39;00m \u001B[39mValueError\u001B[39;00m(\n\u001B[1;32m   1808\u001B[0m         \u001B[39mf\u001B[39m\u001B[39m\"\u001B[39m\u001B[39mExpected \u001B[39m\u001B[39m'\u001B[39m\u001B[39mindex\u001B[39m\u001B[39m'\u001B[39m\u001B[39m, \u001B[39m\u001B[39m'\u001B[39m\u001B[39mcolumns\u001B[39m\u001B[39m'\u001B[39m\u001B[39m or \u001B[39m\u001B[39m'\u001B[39m\u001B[39mtight\u001B[39m\u001B[39m'\u001B[39m\u001B[39m for orient parameter. \u001B[39m\u001B[39m\"\u001B[39m\n\u001B[1;32m   1809\u001B[0m         \u001B[39mf\u001B[39m\u001B[39m\"\u001B[39m\u001B[39mGot \u001B[39m\u001B[39m'\u001B[39m\u001B[39m{\u001B[39;00morient\u001B[39m}\u001B[39;00m\u001B[39m'\u001B[39m\u001B[39m instead\u001B[39m\u001B[39m\"\u001B[39m\n\u001B[1;32m   1810\u001B[0m     )\n\u001B[1;32m   1812\u001B[0m \u001B[39mif\u001B[39;00m orient \u001B[39m!=\u001B[39m \u001B[39m\"\u001B[39m\u001B[39mtight\u001B[39m\u001B[39m\"\u001B[39m:\n\u001B[0;32m-> 1813\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39mcls\u001B[39;49m(data, index\u001B[39m=\u001B[39;49mindex, columns\u001B[39m=\u001B[39;49mcolumns, dtype\u001B[39m=\u001B[39;49mdtype)\n\u001B[1;32m   1814\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[1;32m   1815\u001B[0m     realdata \u001B[39m=\u001B[39m data[\u001B[39m\"\u001B[39m\u001B[39mdata\u001B[39m\u001B[39m\"\u001B[39m]\n",
      "File \u001B[0;32m~/Library/CloudStorage/OneDrive-epfl.ch/Fall 2023/CS-401 Applied Data Analysis (ADA)/GitHub/ada-2023-project-amonavis/amonavis/lib/python3.9/site-packages/pandas/core/frame.py:806\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[0;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[1;32m    804\u001B[0m     \u001B[39mif\u001B[39;00m columns \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n\u001B[1;32m    805\u001B[0m         columns \u001B[39m=\u001B[39m ensure_index(columns)\n\u001B[0;32m--> 806\u001B[0m     arrays, columns, index \u001B[39m=\u001B[39m nested_data_to_arrays(\n\u001B[1;32m    807\u001B[0m         \u001B[39m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001B[39;49;00m\n\u001B[1;32m    808\u001B[0m         \u001B[39m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001B[39;49;00m\n\u001B[1;32m    809\u001B[0m         data,\n\u001B[1;32m    810\u001B[0m         columns,\n\u001B[1;32m    811\u001B[0m         index,  \u001B[39m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m    812\u001B[0m         dtype,\n\u001B[1;32m    813\u001B[0m     )\n\u001B[1;32m    814\u001B[0m     mgr \u001B[39m=\u001B[39m arrays_to_mgr(\n\u001B[1;32m    815\u001B[0m         arrays,\n\u001B[1;32m    816\u001B[0m         columns,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    819\u001B[0m         typ\u001B[39m=\u001B[39mmanager,\n\u001B[1;32m    820\u001B[0m     )\n\u001B[1;32m    821\u001B[0m \u001B[39melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Library/CloudStorage/OneDrive-epfl.ch/Fall 2023/CS-401 Applied Data Analysis (ADA)/GitHub/ada-2023-project-amonavis/amonavis/lib/python3.9/site-packages/pandas/core/internals/construction.py:520\u001B[0m, in \u001B[0;36mnested_data_to_arrays\u001B[0;34m(data, columns, index, dtype)\u001B[0m\n\u001B[1;32m    517\u001B[0m \u001B[39mif\u001B[39;00m is_named_tuple(data[\u001B[39m0\u001B[39m]) \u001B[39mand\u001B[39;00m columns \u001B[39mis\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n\u001B[1;32m    518\u001B[0m     columns \u001B[39m=\u001B[39m ensure_index(data[\u001B[39m0\u001B[39m]\u001B[39m.\u001B[39m_fields)\n\u001B[0;32m--> 520\u001B[0m arrays, columns \u001B[39m=\u001B[39m to_arrays(data, columns, dtype\u001B[39m=\u001B[39;49mdtype)\n\u001B[1;32m    521\u001B[0m columns \u001B[39m=\u001B[39m ensure_index(columns)\n\u001B[1;32m    523\u001B[0m \u001B[39mif\u001B[39;00m index \u001B[39mis\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Library/CloudStorage/OneDrive-epfl.ch/Fall 2023/CS-401 Applied Data Analysis (ADA)/GitHub/ada-2023-project-amonavis/amonavis/lib/python3.9/site-packages/pandas/core/internals/construction.py:845\u001B[0m, in \u001B[0;36mto_arrays\u001B[0;34m(data, columns, dtype)\u001B[0m\n\u001B[1;32m    842\u001B[0m     data \u001B[39m=\u001B[39m [\u001B[39mtuple\u001B[39m(x) \u001B[39mfor\u001B[39;00m x \u001B[39min\u001B[39;00m data]\n\u001B[1;32m    843\u001B[0m     arr \u001B[39m=\u001B[39m _list_to_arrays(data)\n\u001B[0;32m--> 845\u001B[0m content, columns \u001B[39m=\u001B[39m _finalize_columns_and_data(arr, columns, dtype)\n\u001B[1;32m    846\u001B[0m \u001B[39mreturn\u001B[39;00m content, columns\n",
      "File \u001B[0;32m~/Library/CloudStorage/OneDrive-epfl.ch/Fall 2023/CS-401 Applied Data Analysis (ADA)/GitHub/ada-2023-project-amonavis/amonavis/lib/python3.9/site-packages/pandas/core/internals/construction.py:942\u001B[0m, in \u001B[0;36m_finalize_columns_and_data\u001B[0;34m(content, columns, dtype)\u001B[0m\n\u001B[1;32m    939\u001B[0m     columns \u001B[39m=\u001B[39m _validate_or_indexify_columns(contents, columns)\n\u001B[1;32m    940\u001B[0m \u001B[39mexcept\u001B[39;00m \u001B[39mAssertionError\u001B[39;00m \u001B[39mas\u001B[39;00m err:\n\u001B[1;32m    941\u001B[0m     \u001B[39m# GH#26429 do not raise user-facing AssertionError\u001B[39;00m\n\u001B[0;32m--> 942\u001B[0m     \u001B[39mraise\u001B[39;00m \u001B[39mValueError\u001B[39;00m(err) \u001B[39mfrom\u001B[39;00m \u001B[39merr\u001B[39;00m\n\u001B[1;32m    944\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mlen\u001B[39m(contents) \u001B[39mand\u001B[39;00m contents[\u001B[39m0\u001B[39m]\u001B[39m.\u001B[39mdtype \u001B[39m==\u001B[39m np\u001B[39m.\u001B[39mobject_:\n\u001B[1;32m    945\u001B[0m     contents \u001B[39m=\u001B[39m convert_object_array(contents, dtype\u001B[39m=\u001B[39mdtype)\n",
      "\u001B[0;31mValueError\u001B[0m: 6 columns passed, passed data had 8 columns"
     ]
    }
   ],
   "source": [
    "resulting_df = pd.DataFrame.from_dict(result_dict, orient='index', \n",
    "                                      columns=['Source', 'Target', 'Path_1', 'Explored_1', 'Path_2', 'Explored_2'])\n",
    "\n",
    "resulting_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5455c898591c8390",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T20:32:43.817367100Z",
     "start_time": "2023-12-08T20:32:43.810211500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'machine_data_runs_0_6000.csv'"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'machine_data_runs_' + str(chosen_split[0]) + '_' + str(chosen_split[1]) + '.csv'\n",
    "resulting_df.to_csv(name, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750dfc281c120dd6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_read = pd.read_csv('machine_data_runs.csv')\n",
    "test_read"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
