{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Landmark approach\n",
    "Previous algorithms take hella long to run, we need simpler alternatives.\n",
    "\n",
    "First idea is the landmark approach.\n",
    "\n",
    "Gist of it is: Pick important nodes as landmarks, calculate shortest distances to and fro these for all other nodes. Just pick the ones with highest degree for this.\n",
    "\n",
    "Then when finding the shortest path, we just compare the landmarks, sum of the two values and pick the shortest path.\n",
    "\n",
    "Do another step of getting the path back, and we're golden"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "266e210074bcf16a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "import data_readers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "import math\n",
    "\n",
    "# networkx\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "\n",
    "# For semantic similarity\n",
    "from urllib.parse import unquote\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "# Python functions in .py file to read data\n",
    "import machine_searchers\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "from tqdm import TqdmWarning\n",
    "warnings.filterwarnings('ignore', category=TqdmWarning)\n",
    "\n",
    "wikispeedia= nx.read_edgelist('../datasets/wikispeedia_paths-and-graph/links.tsv',\n",
    "                              create_using=nx.DiGraph)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T19:17:54.056644600Z",
     "start_time": "2023-12-14T19:17:53.749668200Z"
    }
   },
   "id": "71d68b146fe5700c"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "class LandmarkSearch:\n",
    "    def __init__(self, graph: nx.DiGraph, landmark_num: int = 50):\n",
    "        # Default value should be a function of the size of the graph...\n",
    "        self.landmark_num = landmark_num\n",
    "\n",
    "        self.landmark_node_list = None\n",
    "        \n",
    "        # Empty dictionaries to store info\n",
    "        self.shortest_paths_to_node = {}\n",
    "        self.shortest_paths_from_node = {}\n",
    "        \n",
    "        self.fro_df = None\n",
    "        self.to_df = None\n",
    "        \n",
    "        self.get_landmark_info(graph, landmark_num)\n",
    "        \n",
    "    def get_landmark_info(self, graph: nx.DiGraph, landmark_num: int):\n",
    "        temp = sorted(graph.degree, key=lambda x: x[1], reverse=True)\n",
    "        temp = [elem[0] for elem in temp]\n",
    "        self.landmark_node_list = temp[:landmark_num]\n",
    "        \n",
    "        for elem in self.landmark_node_list:\n",
    "            self.shortest_paths_to_node[elem] = nx.single_target_shortest_path(graph, elem)\n",
    "            self.shortest_paths_from_node[elem] = nx.single_source_shortest_path(graph, elem)\n",
    "            \n",
    "        # Transforming the previous elements into a dict of lengths, because it's important\n",
    "        # But it's a dict of dicts!\n",
    "        paths_to_lengths = {}\n",
    "        paths_fro_lengths = {}\n",
    "\n",
    "        max_length = len(graph.nodes)\n",
    "\n",
    "        for elem in graph.nodes:\n",
    "            paths_fro_lengths[elem] = {}\n",
    "            paths_to_lengths[elem] = {}\n",
    "            for landmark in self.shortest_paths_from_node.keys():\n",
    "                # This extra code is to check if the key exists or not in the dictionaries\n",
    "                \n",
    "                # And fro and to are swapped, but that's because the dicts we save the info to\n",
    "                # are as well.\n",
    "                # So this ends up making sense\n",
    "                if elem in self.shortest_paths_from_node[landmark]:\n",
    "                    paths_to_lengths[elem][landmark] = len(self.shortest_paths_from_node[landmark][elem])\n",
    "                else:\n",
    "                    paths_to_lengths[elem][landmark] = max_length\n",
    "        \n",
    "                if elem in self.shortest_paths_to_node[landmark]:\n",
    "                    paths_fro_lengths[elem][landmark] = len(self.shortest_paths_to_node[landmark][elem])\n",
    "                else:\n",
    "                    paths_fro_lengths[elem][landmark] = max_length\n",
    "                    \n",
    "        # The easy way of distinguishing the two dfs is as follows:\n",
    "        # Get a loc[a, b]\n",
    "        # fro_df will describe distance from b to a\n",
    "        # to_df describes distance from a to b\n",
    "        self.fro_df = pd.DataFrame(paths_fro_lengths)\n",
    "        self.to_df = pd.DataFrame(paths_to_lengths)\n",
    "        \n",
    "    def find_shortest_path(self, source, target):\n",
    "        # For this, I sum up the two and fro somehow, and find the values!\n",
    "        temp_fro = self.fro_df.loc[:, source]\n",
    "        temp_to = self.to_df.loc[:, target]\n",
    "\n",
    "        distances = temp_to + temp_fro\n",
    "        distances.sort_values(inplace=True)\n",
    "        \n",
    "        landmark = distances.index[0]\n",
    "        \n",
    "        # The landmark is the middle point, this tells us the best one\n",
    "        start_path = self.shortest_paths_to_node[landmark][source][:-1]\n",
    "        end_path = self.shortest_paths_from_node[landmark][target]\n",
    "        \n",
    "        final_path = start_path + end_path\n",
    "        \n",
    "        return final_path"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T22:01:00.858978700Z",
     "start_time": "2023-12-14T22:01:00.851977200Z"
    }
   },
   "id": "7c6ecd8869a942fa"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "landmark_search = LandmarkSearch(wikispeedia)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T22:01:05.909913900Z",
     "start_time": "2023-12-14T22:01:03.133967200Z"
    }
   },
   "id": "56576e0a9b72383"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "['DVD', 'Compact_Disc', 'United_States', 'Broadcasting', 'Compact_Disc']"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmark_search.find_shortest_path('DVD', 'Compact_Disc')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T22:03:57.264352700Z",
     "start_time": "2023-12-14T22:03:57.246352800Z"
    }
   },
   "id": "d0ad84dec15fe23c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Okay, it runs and the result makes some sense!\n",
    "\n",
    "We can also see in the example it's not perfect, as it can loop around. This is just a consequence of the way this was created. That's okay tbh!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e43bc4588adf8c48"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
