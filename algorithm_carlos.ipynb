{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7224477,"sourceType":"datasetVersion","datasetId":4182018}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import importlib.util\nif importlib.util.find_spec(\"sentence_transformers\") is None:\n    !pip install sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2023-12-18T20:48:21.685029Z","iopub.execute_input":"2023-12-18T20:48:21.685694Z","iopub.status.idle":"2023-12-18T20:48:21.690864Z","shell.execute_reply.started":"2023-12-18T20:48:21.685652Z","shell.execute_reply":"2023-12-18T20:48:21.689857Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"!pip install scipy==1.11.3\nimport scipy\nprint(\"SciPy version:\", scipy.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T20:48:21.696397Z","iopub.execute_input":"2023-12-18T20:48:21.696662Z","iopub.status.idle":"2023-12-18T20:48:33.491968Z","shell.execute_reply.started":"2023-12-18T20:48:21.696640Z","shell.execute_reply":"2023-12-18T20:48:33.490849Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Requirement already satisfied: scipy==1.11.3 in /opt/conda/lib/python3.10/site-packages (1.11.3)\nRequirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from scipy==1.11.3) (1.24.3)\nSciPy version: 1.11.3\n","output_type":"stream"}]},{"cell_type":"code","source":"import scipy\nimport numpy as np\nprint(\"SciPy version:\", scipy.__version__)\nprint(\"NumPy version:\", np.__version__)\n\nimport sys\nimport os\nimport pandas as pd\nimport networkx as nx\nfrom networkx.drawing.nx_pydot import graphviz_layout\nfrom urllib.parse import unquote\nfrom sentence_transformers import SentenceTransformer\nimport torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nimport time\nimport warnings\nfrom tqdm import TqdmWarning\nwarnings.filterwarnings('ignore', category=TqdmWarning)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T20:48:33.494248Z","iopub.execute_input":"2023-12-18T20:48:33.494557Z","iopub.status.idle":"2023-12-18T20:48:33.504079Z","shell.execute_reply.started":"2023-12-18T20:48:33.494530Z","shell.execute_reply":"2023-12-18T20:48:33.503250Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"SciPy version: 1.11.3\nNumPy version: 1.24.3\n","output_type":"stream"}]},{"cell_type":"code","source":"sys.version","metadata":{"execution":{"iopub.status.busy":"2023-12-18T20:48:33.505260Z","iopub.execute_input":"2023-12-18T20:48:33.505590Z","iopub.status.idle":"2023-12-18T20:48:33.521537Z","shell.execute_reply.started":"2023-12-18T20:48:33.505557Z","shell.execute_reply":"2023-12-18T20:48:33.520619Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:40:32) [GCC 12.3.0]'"},"metadata":{}}]},{"cell_type":"code","source":"import logging\n\n# Assuming the library uses the standard logging module\nlogger = logging.getLogger('sentence_transformers')  # Replace 'library_name' with the actual name\nlogger.setLevel(logging.ERROR)  # Set to ERROR or CRITICAL to reduce verbosity\nlogger2 = logging.getLogger('SentenceTransformer')  # Replace 'library_name' with the actual name\nlogger2.setLevel(logging.ERROR)  # Set to ERROR or CRITICAL to reduce verbosity\n","metadata":{"id":"qeJvKrz0AGov","execution":{"iopub.status.busy":"2023-12-18T20:48:33.522865Z","iopub.execute_input":"2023-12-18T20:48:33.523384Z","iopub.status.idle":"2023-12-18T20:48:33.531854Z","shell.execute_reply.started":"2023-12-18T20:48:33.523358Z","shell.execute_reply":"2023-12-18T20:48:33.530852Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def read_wikispeedia_graph() -> nx.Graph:\n    wikispeedia = nx.read_edgelist('../input/links.tsv',\n                                         create_using=nx.DiGraph)\n    return wikispeedia\n\n\ndef read_finished_paths() -> pd.DataFrame:\n    paths_finished = pd.read_csv('../input/paths_finished.tsv', sep='\\t', skiprows=15,\n                                 names=['hashedIpAddress', 'timestamp', \"durationInSec\", 'path', \"rating\"])\n    paths_finished['first_article'] = paths_finished['path'].apply(lambda x: x.split(';')[0])\n    paths_finished['last_article'] = paths_finished['path'].apply(lambda x: x.split(';')[-1])\n    paths_finished['path_length'] = paths_finished['path'].apply(lambda x: len(x.split(';')))\n    paths_finished['date'] = pd.to_datetime(paths_finished['timestamp'], unit='s')\n    return paths_finished","metadata":{"id":"fbRPP0JGAGov","execution":{"iopub.status.busy":"2023-12-18T20:48:33.535013Z","iopub.execute_input":"2023-12-18T20:48:33.535308Z","iopub.status.idle":"2023-12-18T20:48:33.543420Z","shell.execute_reply.started":"2023-12-18T20:48:33.535284Z","shell.execute_reply":"2023-12-18T20:48:33.542655Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"G = read_wikispeedia_graph()\npagerank = nx.pagerank(G)","metadata":{"id":"BJ3oEKniAGow","execution":{"iopub.status.busy":"2023-12-18T20:48:33.544501Z","iopub.execute_input":"2023-12-18T20:48:33.544737Z","iopub.status.idle":"2023-12-18T20:48:34.669920Z","shell.execute_reply.started":"2023-12-18T20:48:33.544717Z","shell.execute_reply":"2023-12-18T20:48:34.669228Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"finished_paths = read_finished_paths()\nunique_paths = finished_paths[['first_article', 'last_article']].drop_duplicates()\nsources = unique_paths['first_article']\ntargets = unique_paths['last_article']\nunique_paths.sort_values(by=['first_article', 'last_article'], inplace=True)\nunique_paths.reset_index(inplace=True, drop=True)","metadata":{"id":"r52VrgpwAGow","execution":{"iopub.status.busy":"2023-12-18T20:48:34.671026Z","iopub.execute_input":"2023-12-18T20:48:34.671321Z","iopub.status.idle":"2023-12-18T20:48:34.957030Z","shell.execute_reply.started":"2023-12-18T20:48:34.671298Z","shell.execute_reply":"2023-12-18T20:48:34.956108Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"df = finished_paths[['first_article', 'last_article']].copy()\ndf['path'] = df['first_article'] + '_' + df['last_article']\ndf['path_count'] = df.groupby('path')['path'].transform('count')\ndf.drop_duplicates(subset='path', inplace=True)\ndf = df.sort_values('path_count', ascending = False)\ndf = df[df['path_count']>2][['first_article', 'last_article', 'path_count']]\ndf.reset_index(drop=True, inplace=True)\ndf.to_csv('paths_sample.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2023-12-18T20:48:34.958137Z","iopub.execute_input":"2023-12-18T20:48:34.958416Z","iopub.status.idle":"2023-12-18T20:48:35.064294Z","shell.execute_reply.started":"2023-12-18T20:48:34.958392Z","shell.execute_reply":"2023-12-18T20:48:35.063367Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"        first_article          last_article  path_count\n0            Asteroid                Viking        1043\n1               Brain             Telephone        1040\n2             Theatre                 Zebra         905\n3             Pyramid                  Bean         642\n4              Batman                  Wood         148\n...               ...                   ...         ...\n3855              Tin  Political_philosophy           3\n3856  Carcinus_maenas                Riyadh           3\n3857        Afrikaans          Invertebrate           3\n3858         Botswana           Duran_Duran           3\n3859    North_America               England           3\n\n[3860 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>first_article</th>\n      <th>last_article</th>\n      <th>path_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Asteroid</td>\n      <td>Viking</td>\n      <td>1043</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Brain</td>\n      <td>Telephone</td>\n      <td>1040</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Theatre</td>\n      <td>Zebra</td>\n      <td>905</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Pyramid</td>\n      <td>Bean</td>\n      <td>642</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Batman</td>\n      <td>Wood</td>\n      <td>148</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3855</th>\n      <td>Tin</td>\n      <td>Political_philosophy</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3856</th>\n      <td>Carcinus_maenas</td>\n      <td>Riyadh</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3857</th>\n      <td>Afrikaans</td>\n      <td>Invertebrate</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3858</th>\n      <td>Botswana</td>\n      <td>Duran_Duran</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3859</th>\n      <td>North_America</td>\n      <td>England</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>3860 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"unique_paths.head()","metadata":{"id":"MiCd0elYAGow","execution":{"iopub.status.busy":"2023-12-18T20:48:35.065565Z","iopub.execute_input":"2023-12-18T20:48:35.065933Z","iopub.status.idle":"2023-12-18T20:48:35.074886Z","shell.execute_reply.started":"2023-12-18T20:48:35.065888Z","shell.execute_reply":"2023-12-18T20:48:35.073966Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                    first_article          last_article\n0  %E2%82%AC2_commemorative_coins             Irish_Sea\n1                    10th_century          11th_century\n2                    10th_century              Banknote\n3                    10th_century               Country\n4                    10th_century  Harlem_Globetrotters","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>first_article</th>\n      <th>last_article</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>%E2%82%AC2_commemorative_coins</td>\n      <td>Irish_Sea</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10th_century</td>\n      <td>11th_century</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10th_century</td>\n      <td>Banknote</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10th_century</td>\n      <td>Country</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10th_century</td>\n      <td>Harlem_Globetrotters</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"paths_sample = unique_paths.sample(5000).reset_index(drop=True)\npaths_sample.to_csv('paths_sample.csv')","metadata":{"execution":{"iopub.status.busy":"2023-12-18T20:48:35.076014Z","iopub.execute_input":"2023-12-18T20:48:35.076330Z","iopub.status.idle":"2023-12-18T20:48:35.105639Z","shell.execute_reply.started":"2023-12-18T20:48:35.076305Z","shell.execute_reply":"2023-12-18T20:48:35.104795Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"paths_sample","metadata":{"execution":{"iopub.status.busy":"2023-12-18T20:48:35.106772Z","iopub.execute_input":"2023-12-18T20:48:35.107109Z","iopub.status.idle":"2023-12-18T20:48:35.117506Z","shell.execute_reply.started":"2023-12-18T20:48:35.107075Z","shell.execute_reply":"2023-12-18T20:48:35.116641Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"                  first_article                           last_article\n0                    Lake_Tahoe                             All_Blacks\n1                  Mercantilism                                  Linux\n2         Where_Did_Our_Love_Go  Boundary_Waters_Canoe_Area_Wilderness\n3     Electromagnetic_radiation                       William_McKinley\n4                  16th_century                           Adolf_Hitler\n...                         ...                                    ...\n4995                    Ragtime                        German_language\n4996                Miles_Davis                          Impressionism\n4997            Trapdoor_spider                Eris_%28dwarf_planet%29\n4998           J._R._R._Tolkien       Star_Wars_Episode_IV__A_New_Hope\n4999                    Skylark                             George_Fox\n\n[5000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>first_article</th>\n      <th>last_article</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Lake_Tahoe</td>\n      <td>All_Blacks</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Mercantilism</td>\n      <td>Linux</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Where_Did_Our_Love_Go</td>\n      <td>Boundary_Waters_Canoe_Area_Wilderness</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Electromagnetic_radiation</td>\n      <td>William_McKinley</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16th_century</td>\n      <td>Adolf_Hitler</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>Ragtime</td>\n      <td>German_language</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>Miles_Davis</td>\n      <td>Impressionism</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>Trapdoor_spider</td>\n      <td>Eris_%28dwarf_planet%29</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>J._R._R._Tolkien</td>\n      <td>Star_Wars_Episode_IV__A_New_Hope</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>Skylark</td>\n      <td>George_Fox</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## need to define a correct f function","metadata":{"id":"8lldT-5HAGow"}},{"cell_type":"code","source":"model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n\n# Function to get embeddings using sentence transformer\ndef get_embedding(text):\n    return model.encode(text, convert_to_tensor=True)\n\n# Function to perform L2 normalization on the embeddings\ndef l2_normalize(tensor):\n    return tensor / tensor.norm(p=2, dim=0, keepdim=True)\n\n# Function to calculate semantic similarity between two pieces of text\ndef semantic_similarity(word1, word2):\n    embedding1 = get_embedding(word1)\n    embedding2 = get_embedding(word2)\n\n    # L2 normalization of the embeddings (to make sure, although embedding should already be normalized)\n    embedding1_normalized = l2_normalize(embedding1)\n    embedding2_normalized = l2_normalize(embedding2)\n\n    # Compute and return the similarity of normalized tensors\n    return torch.dot(embedding1_normalized, embedding2_normalized).item()\n\ndef get_value(G, node_value, target_value):\n    similarity = semantic_similarity(node_value, target_value)\n\n    # get pagerank of node_value in G\n    node_pagerank = pagerank.get(node_value, None)\n    if similarity < 0.1:\n        f = node_pagerank\n    elif 0.1 <= similarity <= 0.5:\n        f = similarity * node_pagerank\n    else:\n        f = similarity\n    #print(node_value, target_value, f)\n    return f","metadata":{"id":"riM_ZnpfAGox","execution":{"iopub.status.busy":"2023-12-18T20:48:35.118601Z","iopub.execute_input":"2023-12-18T20:48:35.118900Z","iopub.status.idle":"2023-12-18T20:48:41.294308Z","shell.execute_reply.started":"2023-12-18T20:48:35.118877Z","shell.execute_reply":"2023-12-18T20:48:41.293465Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8cb86a6b43d43d7a77f91efb066c3c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"479bfae8d5a84ec79cd2b99b958fdcdd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5f94b0925d94be8b62fb8342c07381f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e95f0162aabd44e98ba926ad7b6aca0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b54f481fa1c8437c8a1edc182d1eb42a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddc21f45ade24fb1943ea4742cd09ad7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"010591960bb64395b6eaeb702fb083d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95b196f4d1eb4c30808228c04835c4c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11fddc122f37467e8f001129d6b848de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"861e00c1159e481dbb9de302d8a44554"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e43ae8e967ed409b913d1e313207f255"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4cd901fa9c74214a1f56e26fa6d0425"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b2320dbb1904ad4874198b7d460ae52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a88e7593c19743fe8d77f5605e4fa6d6"}},"metadata":{}}]},{"cell_type":"markdown","source":"## For a single iteration, print all nodes visited","metadata":{"id":"UzMyutOoAGox"}},{"cell_type":"code","source":"def traverse_graph(graph, start_node, target_node):\n    current_node = start_node\n    visited = []  # List to keep track of visited nodes\n    previous_node = start_node\n    reached_target = False\n    print(f\"Starting at node: {current_node}\")\n\n    for length in range(20):  # Limit to 20 moves\n        if current_node == target_node:\n            print(f\"Target node reached in {length} moves.\")\n            visited.append(previous_node)\n            visited.append(current_node)\n            reached_target = True\n            return length+1, visited, reached_target\n\n        if length!=0: visited.append(previous_node)  # Mark the previous node as visited\n        previous_node = current_node  # We do it like this so we can return to the previous node\n\n        # Check if the current node has neighbors\n        neighbors = list(graph.neighbors(current_node))\n        unvisited_neighbors = [n for n in neighbors if n not in visited and n != current_node]\n\n        if unvisited_neighbors:\n            # Find the neighbor with the highest value by applying get_value\n            next_node = max(unvisited_neighbors, key=lambda n: get_value(G, n, target_node))\n            current_node = next_node\n            print(f\"Moving to node: {current_node}\")\n        else:\n            print(\"No more unvisited neighbors to move to.\")\n            return length+1, visited, reached_target\n\n    print(\"Limit of 20 nodes reached.\")\n    return length+1, visited, reached_target","metadata":{"id":"qnSBziZ7AGox","execution":{"iopub.status.busy":"2023-12-18T20:48:41.295390Z","iopub.execute_input":"2023-12-18T20:48:41.295992Z","iopub.status.idle":"2023-12-18T20:48:41.304957Z","shell.execute_reply.started":"2023-12-18T20:48:41.295964Z","shell.execute_reply":"2023-12-18T20:48:41.304077Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"length, visited, reached =traverse_graph(G, '14th_century', 'Currency')","metadata":{"id":"1qOdngVmAGox","execution":{"iopub.status.busy":"2023-12-18T20:48:41.308037Z","iopub.execute_input":"2023-12-18T20:48:41.308361Z","iopub.status.idle":"2023-12-18T20:48:48.372051Z","shell.execute_reply.started":"2023-12-18T20:48:41.308336Z","shell.execute_reply":"2023-12-18T20:48:48.371009Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Starting at node: 14th_century\nMoving to node: Europe\nMoving to node: United_Kingdom\nMoving to node: Currency\nTarget node reached in 3 moves.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## For more iterations, don't print anything","metadata":{"id":"LofZ6TfCAGoy"}},{"cell_type":"code","source":"def traverse_graph_no_print(graph, start_node, target_node):\n    current_node = start_node\n    visited = []  # List to keep track of visited nodes\n    previous_node = start_node\n    reached_target = False\n    #print(f\"Starting at node: {current_node}\")\n\n    for length in range(20):  # Limit to 20 moves\n        if current_node == target_node:\n            #print(f\"Target node reached in {len} moves.\")\n            visited.append(previous_node)\n            visited.append(current_node)\n            reached_target = True\n            return length+1, visited, reached_target\n\n        if length!=0: visited.append(previous_node)  # Mark the previous node as visited\n        previous_node = current_node  # We do it like this so we can return to the previous node\n\n        # Check if the current node has neighbors\n        neighbors = list(graph.neighbors(current_node))\n        unvisited_neighbors = [n for n in neighbors if n not in visited and n != current_node]\n\n        if unvisited_neighbors:\n            # Find the neighbor with the highest value by applying get_value\n            next_node = max(unvisited_neighbors, key=lambda n: get_value(G, n, target_node))\n            current_node = next_node\n            #print(f\"Moving to node: {current_node}\")\n        else:\n            #print(\"No more unvisited neighbors to move to.\")\n            return length+1, visited, reached_target\n\n    #print(\"Limit of 20 nodes reached.\")\n    return length+1, visited, reached_target","metadata":{"id":"2z88z_1GAGoy","execution":{"iopub.status.busy":"2023-12-18T20:48:48.373159Z","iopub.execute_input":"2023-12-18T20:48:48.373436Z","iopub.status.idle":"2023-12-18T20:48:48.381857Z","shell.execute_reply.started":"2023-12-18T20:48:48.373405Z","shell.execute_reply":"2023-12-18T20:48:48.380984Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from itertools import islice\n\n# Initialize empty lists to store results\nresults = []\ni = 0\n\n# Record the start time\nstart_time = time.time()\n\n#for index, row in df.iterrows():\nfor index, row in islice(df.iterrows(), 1000, None):\n\n    source = row['first_article']\n    target = row['last_article']\n\n    # Assuming you have the traverse_graph function as described earlier\n    length, visited, reached = traverse_graph_no_print(G, source, target)\n\n    # Create a dictionary for the current result\n    result_dict = {\n        'source': source,\n        'target': target,\n        'reached': reached,\n        'length': length,\n        'visited': visited\n    }\n\n    results.append(result_dict)\n\n    print(index)\n    i += 1\n    if i > 1000:\n        break\n\n\n# Calculate the end time and the duration\nend_time = time.time()\nduration = end_time - start_time\nprint(\"Duration: \", duration)\n\n# Create a DataFrame from the list of dictionaries\nresult_df = pd.DataFrame(results)","metadata":{"id":"AThw2ycLAGoy","execution":{"iopub.status.busy":"2023-12-18T20:48:48.382909Z","iopub.execute_input":"2023-12-18T20:48:48.383167Z","iopub.status.idle":"2023-12-18T20:48:53.950201Z","shell.execute_reply.started":"2023-12-18T20:48:48.383144Z","shell.execute_reply":"2023-12-18T20:48:53.948785Z"},"trusted":true},"execution_count":32,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m target \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_article\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Assuming you have the traverse_graph function as described earlier\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m length, visited, reached \u001b[38;5;241m=\u001b[39m \u001b[43mtraverse_graph_no_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Create a dictionary for the current result\u001b[39;00m\n\u001b[1;32m     20\u001b[0m result_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m'\u001b[39m: source,\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m: target,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisited\u001b[39m\u001b[38;5;124m'\u001b[39m: visited\n\u001b[1;32m     26\u001b[0m }\n","Cell \u001b[0;32mIn[31], line 25\u001b[0m, in \u001b[0;36mtraverse_graph_no_print\u001b[0;34m(graph, start_node, target_node)\u001b[0m\n\u001b[1;32m     21\u001b[0m unvisited_neighbors \u001b[38;5;241m=\u001b[39m [n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m neighbors \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m visited \u001b[38;5;129;01mand\u001b[39;00m n \u001b[38;5;241m!=\u001b[39m current_node]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unvisited_neighbors:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Find the neighbor with the highest value by applying get_value\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     next_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munvisited_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_node\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     current_node \u001b[38;5;241m=\u001b[39m next_node\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m#print(f\"Moving to node: {current_node}\")\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m#print(\"No more unvisited neighbors to move to.\")\u001b[39;00m\n","Cell \u001b[0;32mIn[31], line 25\u001b[0m, in \u001b[0;36mtraverse_graph_no_print.<locals>.<lambda>\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m     21\u001b[0m unvisited_neighbors \u001b[38;5;241m=\u001b[39m [n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m neighbors \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m visited \u001b[38;5;129;01mand\u001b[39;00m n \u001b[38;5;241m!=\u001b[39m current_node]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unvisited_neighbors:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Find the neighbor with the highest value by applying get_value\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     next_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(unvisited_neighbors, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m n: \u001b[43mget_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_node\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     26\u001b[0m     current_node \u001b[38;5;241m=\u001b[39m next_node\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m#print(f\"Moving to node: {current_node}\")\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m#print(\"No more unvisited neighbors to move to.\")\u001b[39;00m\n","Cell \u001b[0;32mIn[28], line 24\u001b[0m, in \u001b[0;36mget_value\u001b[0;34m(G, node_value, target_value)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_value\u001b[39m(G, node_value, target_value):\n\u001b[0;32m---> 24\u001b[0m     similarity \u001b[38;5;241m=\u001b[39m \u001b[43msemantic_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# get pagerank of node_value in G\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     node_pagerank \u001b[38;5;241m=\u001b[39m pagerank\u001b[38;5;241m.\u001b[39mget(node_value, \u001b[38;5;28;01mNone\u001b[39;00m)\n","Cell \u001b[0;32mIn[28], line 14\u001b[0m, in \u001b[0;36msemantic_similarity\u001b[0;34m(word1, word2)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msemantic_similarity\u001b[39m(word1, word2):\n\u001b[1;32m     13\u001b[0m     embedding1 \u001b[38;5;241m=\u001b[39m get_embedding(word1)\n\u001b[0;32m---> 14\u001b[0m     embedding2 \u001b[38;5;241m=\u001b[39m \u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# L2 normalization of the embeddings (to make sure, although embedding should already be normalized)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     embedding1_normalized \u001b[38;5;241m=\u001b[39m l2_normalize(embedding1)\n","Cell \u001b[0;32mIn[28], line 5\u001b[0m, in \u001b[0;36mget_embedding\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embedding\u001b[39m(text):\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:161\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start_index \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sentences), batch_size, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatches\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m    160\u001b[0m     sentences_batch \u001b[38;5;241m=\u001b[39m sentences_sorted[start_index:start_index\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m--> 161\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m     features \u001b[38;5;241m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:319\u001b[0m, in \u001b[0;36mSentenceTransformer.tokenize\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: Union[List[\u001b[38;5;28mstr\u001b[39m], List[Dict], List[Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]]):\n\u001b[1;32m    316\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m    Tokenizes the texts\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_first_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:113\u001b[0m, in \u001b[0;36mTransformer.tokenize\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_lower_case:\n\u001b[1;32m    111\u001b[0m     to_tokenize \u001b[38;5;241m=\u001b[39m [[s\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m col] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m to_tokenize]\n\u001b[0;32m--> 113\u001b[0m output\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mto_tokenize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlongest_first\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2802\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2800\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2801\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2802\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2804\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2888\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2883\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2884\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2885\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2886\u001b[0m         )\n\u001b[1;32m   2887\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 2888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2890\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2895\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2896\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2897\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2898\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2902\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2905\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2906\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2907\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2908\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   2909\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   2910\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2927\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3079\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3069\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3070\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3071\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3072\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3076\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3077\u001b[0m )\n\u001b[0;32m-> 3079\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3081\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3096\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3097\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"result_df","metadata":{"id":"_PdLbjIQAGoy","execution":{"iopub.status.busy":"2023-12-18T20:48:53.951003Z","iopub.status.idle":"2023-12-18T20:48:53.951370Z","shell.execute_reply.started":"2023-12-18T20:48:53.951175Z","shell.execute_reply":"2023-12-18T20:48:53.951213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Export the dataframe","metadata":{"id":"-P63ZI1vAGoz"}},{"cell_type":"code","source":"result_df.to_csv('machine_paths.csv', index=False)","metadata":{"id":"ezY0PeXGAGoz","execution":{"iopub.status.busy":"2023-12-18T20:48:53.952563Z","iopub.status.idle":"2023-12-18T20:48:53.952923Z","shell.execute_reply.started":"2023-12-18T20:48:53.952751Z","shell.execute_reply":"2023-12-18T20:48:53.952769Z"},"trusted":true},"execution_count":null,"outputs":[]}]}