{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Deliverable 2\n",
    "This is the notebook that has the second deliverable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import modules\n",
    "Feel free to use the virtual environment (amonavis) included in the GitHub folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:52:01.897273Z",
     "start_time": "2023-11-16T14:51:42.946886900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt \n",
    "import networkx as nx\n",
    "\n",
    "# For semantic similarity\n",
    "from urllib.parse import unquote\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Python functions in .py file to read data\n",
    "import data_readers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1. Data reading\n",
    "The following code reads the data and saves them in the appropriate variables.\n",
    "\n",
    "<br><br><br>\n",
    "**finished_paths**\n",
    "\n",
    "The datafile includes the hashedIpAddress, timestamp, durationInSec, path, and rating.\n",
    "\n",
    "We also add columns with the first article (soruce), last article (target), path length (#articles), and a readable date in Timestamp format.\n",
    "\n",
    "<br><br>\n",
    "**articles**\n",
    "\n",
    "Dataframe with the name of all articles in the dataset.\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "\n",
    "<div style=\"border: 2px solid white; padding: 10px;\">\n",
    "    <font color=\"red\">please briefly describe the other files. As I only worked with finished_paths and articles, I guess it's better if someone who used them does that. Also add a sample of how each data looks like. </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T14:55:34.316451500Z",
     "start_time": "2023-11-16T14:52:01.907382400Z"
    }
   },
   "outputs": [],
   "source": [
    "# The links and edges\n",
    "wikispeedia = data_readers.read_wikispeedia_graph()\n",
    "\n",
    "# The finished paths\n",
    "finished_paths = data_readers.read_finished_paths()\n",
    "\n",
    "# The unfinished paths\n",
    "unfinished_paths = data_readers.read_unfinished_paths()\n",
    "\n",
    "# List of all articles\n",
    "articles = data_readers.read_articles()\n",
    "\n",
    "# We found out later that the data contained in the shortest path matrix given to us seems to be wrong\n",
    "# Here we also add a quick dictionary that properly shows that this is wrong, and give an example\n",
    "shortest_path_df = data_readers.read_shortest_path_df()\n",
    "shortest_path_dict = dict(nx.all_pairs_shortest_path(wikispeedia))\n",
    "\n",
    "# Searching for the string of a given article. It has to be formatted like the article name\n",
    "# Which shouldn't be a problem, as we'll probably usually retrieve them internally\n",
    "obi_wan_text = data_readers.plaintext_article_finder('Obi-Wan_Kenobi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:55:34.356435700Z",
     "start_time": "2023-11-16T14:55:34.327611200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 4592 nodes\n",
      "Dataset has 119882 edges\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset has\", len(wikispeedia.nodes), \"nodes\")\n",
    "print(\"Dataset has\", len(wikispeedia.edges), \"edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "These are less nodes than the reported number, it should be 4,604 nodes.\n",
    "\n",
    "The 119,882 edges is correct though.\n",
    "\n",
    "The difference is probably due to some nodes not being connected to the rest of the graph, as here we read in only the articles that are connected. The few nodes that we are losing do not matter for what we need"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:55:34.435311Z",
     "start_time": "2023-11-16T14:55:34.347850700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        hashedIpAddress   timestamp  durationInSec  \\\n23203  461a9f80797f6406  1363697997            429   \n2968   28bd91e879d8ea9d  1344855924             57   \n6351   18905b8f2635f996  1372167354             32   \n49607  5cc47df267db4d3f  1248727556             51   \n31818  12c3d3316114fb01  1302276264             20   \n\n                                                    path  rating  \\\n23203  Formic_acid;Alchemy;Frankenstein;Popular_cultu...     NaN   \n2968   Cat;Dutch_language;Netherlands;Nazi_Germany;Ad...     NaN   \n6351   Mormon;Christianity;Southern_Africa;Democratic...     1.0   \n49607  Troodon;North_America;United_States;President_...     1.0   \n31818             Oppression;Psychology;Biology;Organism     1.0   \n\n      first_article                   last_article  path_length  \\\n23203   Formic_acid  John_F._Kennedy_assassination            9   \n2968            Cat                   Adolf_Hitler            5   \n6351         Mormon          Republic_of_the_Congo            5   \n49607       Troodon                  James_K._Polk            5   \n31818    Oppression                       Organism            4   \n\n                     date  \n23203 2013-03-19 12:59:57  \n2968  2012-08-13 11:05:24  \n6351  2013-06-25 13:35:54  \n49607 2009-07-27 20:45:56  \n31818 2011-04-08 15:24:24  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hashedIpAddress</th>\n      <th>timestamp</th>\n      <th>durationInSec</th>\n      <th>path</th>\n      <th>rating</th>\n      <th>first_article</th>\n      <th>last_article</th>\n      <th>path_length</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23203</th>\n      <td>461a9f80797f6406</td>\n      <td>1363697997</td>\n      <td>429</td>\n      <td>Formic_acid;Alchemy;Frankenstein;Popular_cultu...</td>\n      <td>NaN</td>\n      <td>Formic_acid</td>\n      <td>John_F._Kennedy_assassination</td>\n      <td>9</td>\n      <td>2013-03-19 12:59:57</td>\n    </tr>\n    <tr>\n      <th>2968</th>\n      <td>28bd91e879d8ea9d</td>\n      <td>1344855924</td>\n      <td>57</td>\n      <td>Cat;Dutch_language;Netherlands;Nazi_Germany;Ad...</td>\n      <td>NaN</td>\n      <td>Cat</td>\n      <td>Adolf_Hitler</td>\n      <td>5</td>\n      <td>2012-08-13 11:05:24</td>\n    </tr>\n    <tr>\n      <th>6351</th>\n      <td>18905b8f2635f996</td>\n      <td>1372167354</td>\n      <td>32</td>\n      <td>Mormon;Christianity;Southern_Africa;Democratic...</td>\n      <td>1.0</td>\n      <td>Mormon</td>\n      <td>Republic_of_the_Congo</td>\n      <td>5</td>\n      <td>2013-06-25 13:35:54</td>\n    </tr>\n    <tr>\n      <th>49607</th>\n      <td>5cc47df267db4d3f</td>\n      <td>1248727556</td>\n      <td>51</td>\n      <td>Troodon;North_America;United_States;President_...</td>\n      <td>1.0</td>\n      <td>Troodon</td>\n      <td>James_K._Polk</td>\n      <td>5</td>\n      <td>2009-07-27 20:45:56</td>\n    </tr>\n    <tr>\n      <th>31818</th>\n      <td>12c3d3316114fb01</td>\n      <td>1302276264</td>\n      <td>20</td>\n      <td>Oppression;Psychology;Biology;Organism</td>\n      <td>1.0</td>\n      <td>Oppression</td>\n      <td>Organism</td>\n      <td>4</td>\n      <td>2011-04-08 15:24:24</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finished_paths.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:55:34.441823900Z",
     "start_time": "2023-11-16T14:55:34.393588800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        hashedIpAddress   timestamp  durationInSec  \\\n18904  206c212604a78fb1  1368019245             73   \n5871   106a395641982357  1317225145           1911   \n13498  1e1846581384e33e  1350893596            107   \n20506  4d8e50314258ad1d  1374008831              6   \n10581  576357c67f621837  1344900692           1900   \n\n                                                    path      target     type  \n18904  Battle_of_Normandy;Nazi_Germany;Adolf_Hitler;J...   Reza_Shah  restart  \n5871   Magic__The_Gathering;Board_game;Iran;Islam;Mid...  Al_Jazeera  timeout  \n13498  Statue_of_Zeus_at_Olympia;Greece;Climate;Weath...     Pumpkin  restart  \n20506                                        Visual_arts     Parsley  restart  \n10581        Brain;Computer_science;Internet;Advertising   Telephone  timeout  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hashedIpAddress</th>\n      <th>timestamp</th>\n      <th>durationInSec</th>\n      <th>path</th>\n      <th>target</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18904</th>\n      <td>206c212604a78fb1</td>\n      <td>1368019245</td>\n      <td>73</td>\n      <td>Battle_of_Normandy;Nazi_Germany;Adolf_Hitler;J...</td>\n      <td>Reza_Shah</td>\n      <td>restart</td>\n    </tr>\n    <tr>\n      <th>5871</th>\n      <td>106a395641982357</td>\n      <td>1317225145</td>\n      <td>1911</td>\n      <td>Magic__The_Gathering;Board_game;Iran;Islam;Mid...</td>\n      <td>Al_Jazeera</td>\n      <td>timeout</td>\n    </tr>\n    <tr>\n      <th>13498</th>\n      <td>1e1846581384e33e</td>\n      <td>1350893596</td>\n      <td>107</td>\n      <td>Statue_of_Zeus_at_Olympia;Greece;Climate;Weath...</td>\n      <td>Pumpkin</td>\n      <td>restart</td>\n    </tr>\n    <tr>\n      <th>20506</th>\n      <td>4d8e50314258ad1d</td>\n      <td>1374008831</td>\n      <td>6</td>\n      <td>Visual_arts</td>\n      <td>Parsley</td>\n      <td>restart</td>\n    </tr>\n    <tr>\n      <th>10581</th>\n      <td>576357c67f621837</td>\n      <td>1344900692</td>\n      <td>1900</td>\n      <td>Brain;Computer_science;Internet;Advertising</td>\n      <td>Telephone</td>\n      <td>timeout</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfinished_paths.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:55:34.531608800Z",
     "start_time": "2023-11-16T14:55:34.414214200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                            articles\n3514              Robert_Oppenheimer\n2224                       Jane_Eyre\n4103     Theatre_Royal%2C_Drury_Lane\n811   Carlsbad_Caverns_National_Park\n3428    Raising_the_Flag_on_Iwo_Jima",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>articles</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3514</th>\n      <td>Robert_Oppenheimer</td>\n    </tr>\n    <tr>\n      <th>2224</th>\n      <td>Jane_Eyre</td>\n    </tr>\n    <tr>\n      <th>4103</th>\n      <td>Theatre_Royal%2C_Drury_Lane</td>\n    </tr>\n    <tr>\n      <th>811</th>\n      <td>Carlsbad_Caverns_National_Park</td>\n    </tr>\n    <tr>\n      <th>3428</th>\n      <td>Raising_the_Flag_on_Iwo_Jima</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:55:34.531608800Z",
     "start_time": "2023-11-16T14:55:34.429908300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                     (%C3%81ed%C3%A1n_mac_Gabr%C3%A1in,)  \\\n(%C3%81ed%C3%A1n_mac_Gabr%C3%A1in,)                                    0   \n(%C3%85land,)                                                         -1   \n(%C3%89douard_Manet,)                                                 -1   \n(%C3%89ire,)                                                          -1   \n(%C3%93engus_I_of_the_Picts,)                                         -1   \n\n                                     (%C3%85land,)  (%C3%89douard_Manet,)  \\\n(%C3%81ed%C3%A1n_mac_Gabr%C3%A1in,)             -1                     -1   \n(%C3%85land,)                                    0                     -1   \n(%C3%89douard_Manet,)                           -1                      0   \n(%C3%89ire,)                                    -1                     -1   \n(%C3%93engus_I_of_the_Picts,)                   -1                     -1   \n\n                                     (%C3%89ire,)  \\\n(%C3%81ed%C3%A1n_mac_Gabr%C3%A1in,)            -1   \n(%C3%85land,)                                  -1   \n(%C3%89douard_Manet,)                          -1   \n(%C3%89ire,)                                    0   \n(%C3%93engus_I_of_the_Picts,)                  -1   \n\n                                     (%C3%93engus_I_of_the_Picts,)  \\\n(%C3%81ed%C3%A1n_mac_Gabr%C3%A1in,)                             -1   \n(%C3%85land,)                                                   -1   \n(%C3%89douard_Manet,)                                           -1   \n(%C3%89ire,)                                                    -1   \n(%C3%93engus_I_of_the_Picts,)                                    0   \n\n                                     (%E2%82%AC2_commemorative_coins,)  \\\n(%C3%81ed%C3%A1n_mac_Gabr%C3%A1in,)                                 -1   \n(%C3%85land,)                                                       -1   \n(%C3%89douard_Manet,)                                               -1   \n(%C3%89ire,)                                                        -1   \n(%C3%93engus_I_of_the_Picts,)                                       -1   \n\n                                     (10th_century,)  (11th_century,)  \\\n(%C3%81ed%C3%A1n_mac_Gabr%C3%A1in,)                3                3   \n(%C3%85land,)                                      2                2   \n(%C3%89douard_Manet,)                              3                3   \n(%C3%89ire,)                                       3                3   \n(%C3%93engus_I_of_the_Picts,)                      2                2   \n\n                                     (12th_century,)  (13th_century,)  ...  \\\n(%C3%81ed%C3%A1n_mac_Gabr%C3%A1in,)                3                3  ...   \n(%C3%85land,)                                      2                2  ...   \n(%C3%89douard_Manet,)                              2                2  ...   \n(%C3%89ire,)                                       3                3  ...   \n(%C3%93engus_I_of_the_Picts,)                      3                2  ...   \n\n                                     (Ziad_Jarrah,)  (Zimbabwe,)  (Zinc,)  \\\n(%C3%81ed%C3%A1n_mac_Gabr%C3%A1in,)               4            3        3   \n(%C3%85land,)                                     4            2        3   \n(%C3%89douard_Manet,)                             4            3        2   \n(%C3%89ire,)                                      4            2        2   \n(%C3%93engus_I_of_the_Picts,)                     4            2        3   \n\n                                     (Zinc_chloride,)  (Zion_National_Park,)  \\\n(%C3%81ed%C3%A1n_mac_Gabr%C3%A1in,)                 4                      4   \n(%C3%85land,)                                       4                      4   \n(%C3%89douard_Manet,)                               3                      4   \n(%C3%89ire,)                                        3                      4   \n(%C3%93engus_I_of_the_Picts,)                       4                      4   \n\n                                     (Zionism,)  (Zirconium,)  (Zoroaster,)  \\\n(%C3%81ed%C3%A1n_mac_Gabr%C3%A1in,)           3             4             4   \n(%C3%85land,)                                 3             4             3   \n(%C3%89douard_Manet,)                         3             4             3   \n(%C3%89ire,)                                  3             4             4   \n(%C3%93engus_I_of_the_Picts,)                 3             4             3   \n\n                                     (Zuid-Gelders,)  (Zulu,)  \n(%C3%81ed%C3%A1n_mac_Gabr%C3%A1in,)                4        2  \n(%C3%85land,)                                      3        3  \n(%C3%89douard_Manet,)                              3        3  \n(%C3%89ire,)                                       3        3  \n(%C3%93engus_I_of_the_Picts,)                      3        3  \n\n[5 rows x 4604 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>(%C3%81ed%C3%A1n_mac_Gabr%C3%A1in,)</th>\n      <th>(%C3%85land,)</th>\n      <th>(%C3%89douard_Manet,)</th>\n      <th>(%C3%89ire,)</th>\n      <th>(%C3%93engus_I_of_the_Picts,)</th>\n      <th>(%E2%82%AC2_commemorative_coins,)</th>\n      <th>(10th_century,)</th>\n      <th>(11th_century,)</th>\n      <th>(12th_century,)</th>\n      <th>(13th_century,)</th>\n      <th>...</th>\n      <th>(Ziad_Jarrah,)</th>\n      <th>(Zimbabwe,)</th>\n      <th>(Zinc,)</th>\n      <th>(Zinc_chloride,)</th>\n      <th>(Zion_National_Park,)</th>\n      <th>(Zionism,)</th>\n      <th>(Zirconium,)</th>\n      <th>(Zoroaster,)</th>\n      <th>(Zuid-Gelders,)</th>\n      <th>(Zulu,)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>(%C3%81ed%C3%A1n_mac_Gabr%C3%A1in,)</th>\n      <td>0</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>(%C3%85land,)</th>\n      <td>-1</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>(%C3%89douard_Manet,)</th>\n      <td>-1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>(%C3%89ire,)</th>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>(%C3%93engus_I_of_the_Picts,)</th>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 4604 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortest_path_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Issue with the shortest path\n",
    "The shortest paths that were calculated are wrong. This is just a simple example to show that at least one of the points is wrong. We assume this is common enough elsewhere, as the effort needed to properly prove this is too large.\n",
    "\n",
    "We double-checked the method for reading in the data, and there are no big changes to be done there. We also double-checked that the graph is a directed graph, which matters for this search. Additionally, we manually checked the edges, so we know that the following example is correct."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest path from Actor to Japan in the given matrix is: 3\n",
      "Shortest path from Actor to Japan according to networkX is: 1\n",
      "The actual path is: ['Actor', 'Japan']\n"
     ]
    }
   ],
   "source": [
    "print(\"Shortest path from Actor to Japan in the given matrix is:\", shortest_path_df[('Actor',)][('Japan',)])\n",
    "\n",
    "print(\"Shortest path from Actor to Japan according to networkX is:\", len(shortest_path_dict['Actor']['Japan'])-1)\n",
    "\n",
    "print(\"The actual path is:\", shortest_path_dict['Actor']['Japan'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T14:57:12.909123100Z",
     "start_time": "2023-11-16T14:57:12.787855200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:55:34.718918700Z",
     "start_time": "2023-11-16T14:55:34.482388700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'   #copyright\\n\\nObi-Wan Kenobi\\n\\n2007 Schools Wikipedia Selection. Related subjects: Films\\n\\n   Star Wa'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No need to print the entire text, just show that reading it in works\n",
    "obi_wan_text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Study of Unique Paths\n",
    "Here we study the unique source and target pairs. We will use the dataframes to compare the performance between humans and machines, as well as to know what paths to make machines complete.\n",
    "\n",
    "**article_combinations**\n",
    "\n",
    "This dataframe contains information on all the combination of source and target articles in the finished games (paths). It includes how many times it has been played, and the mean and std of the path length, duration of the game, and rating.\n",
    "\n",
    "**unique_targets** and **unique_sources**\n",
    "\n",
    "These dataframes include all the sources and targets that appears in the finished games\n",
    "\n",
    "<br><br>\n",
    "Note that we don't change to ASCII the name of the articles yet. We will do it at a later step if we need to.\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<div style=\"border: 2px solid white; padding: 10px;\">\n",
    "    <font color=\"red\">feel free to move this wherever works better. Maybe not the best thing to have at the beginning of the notebook.</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:55:35.252365700Z",
     "start_time": "2023-11-16T14:55:34.504813900Z"
    }
   },
   "outputs": [],
   "source": [
    "# How many each pair of articles has been visited\n",
    "article_combinations_count = finished_paths.groupby(['first_article', 'last_article']).size().reset_index(name='count')\n",
    "\n",
    "# The mean and std of the path length for each pair of articles\n",
    "article_combinations_stats = finished_paths.groupby(['first_article', 'last_article'])['path_length'].agg(['mean', 'std']).reset_index()\n",
    "article_combinations_stats['std'] = article_combinations_stats['std'].fillna(0)\n",
    "article_combinations_stats.rename(columns={'mean': 'mean_length', 'std': 'std_length'}, inplace=True)\n",
    "\n",
    "# The mean and std of the rating for each pair of articles. \n",
    "    # Note that mean and std may be nan if there are nan ratings. We purposely leave them as nan, as we don't want to fill them with 0s or 1s.\n",
    "    # Depending on the application, we could change this in the future if neeeded.\n",
    "rating_combinations_stats_rating = finished_paths.groupby(['first_article', 'last_article'])['rating'].agg(['mean', 'std']).reset_index()\n",
    "#rating_combinations_stats_rating['std'] = rating_combinations_stats_rating['std'].fillna(0)\n",
    "mask = rating_combinations_stats_rating['mean'].notnull()\n",
    "rating_combinations_stats_rating.loc[mask, 'std'] = rating_combinations_stats_rating.loc[mask, 'std'].fillna(0)\n",
    "rating_combinations_stats_rating.rename(columns={'mean': 'mean_rating', 'std': 'std_rating'}, inplace=True)\n",
    "\n",
    "# The mean and std of the time for each pair of articles.\n",
    "rating_combinations_stats_time = finished_paths.groupby(['first_article', 'last_article'])['durationInSec'].agg(['mean', 'std']).reset_index()\n",
    "rating_combinations_stats_time['std'] = rating_combinations_stats_time['std'].fillna(0)\n",
    "rating_combinations_stats_time.rename(columns={'mean': 'mean_durationInSec', 'std': 'std_durationInSec'}, inplace=True)\n",
    "\n",
    "# Merging all the dataframes\n",
    "article_combinations = pd.merge(article_combinations_count, article_combinations_stats, on=['first_article', 'last_article'])\n",
    "article_combinations = pd.merge(article_combinations, rating_combinations_stats_rating, on=['first_article', 'last_article'])\n",
    "article_combinations = pd.merge(article_combinations, rating_combinations_stats_time, on=['first_article', 'last_article'])\n",
    "\n",
    "# The number of unique sources and targets\n",
    "unique_sources = finished_paths['first_article'].value_counts().reset_index()\n",
    "unique_targets = finished_paths['last_article'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:55:35.264763Z",
     "start_time": "2023-11-16T14:55:34.819825500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                     first_article  \\\n17040  Meteorological_history_of_Hurricane_Katrina   \n27458                                         Vole   \n26961                        University_of_Chicago   \n4153                                    Bob_Marley   \n9887                                       Florida   \n\n                         last_article  count  mean_length  std_length  \\\n17040                        Quantity      2          9.5    3.535534   \n27458               Strait_of_Malacca      1          8.0    0.000000   \n26961                       Reggaeton      1          3.0    0.000000   \n4153                            Earth      1          4.0    0.000000   \n9887   The_Championships%2C_Wimbledon      1          8.0    0.000000   \n\n       mean_rating  std_rating  mean_durationInSec  std_durationInSec  \n17040          3.0         0.0               244.0          22.627417  \n27458          NaN         NaN               102.0           0.000000  \n26961          1.0         0.0                64.0           0.000000  \n4153           NaN         NaN                33.0           0.000000  \n9887           3.0         0.0               111.0           0.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>first_article</th>\n      <th>last_article</th>\n      <th>count</th>\n      <th>mean_length</th>\n      <th>std_length</th>\n      <th>mean_rating</th>\n      <th>std_rating</th>\n      <th>mean_durationInSec</th>\n      <th>std_durationInSec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17040</th>\n      <td>Meteorological_history_of_Hurricane_Katrina</td>\n      <td>Quantity</td>\n      <td>2</td>\n      <td>9.5</td>\n      <td>3.535534</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>244.0</td>\n      <td>22.627417</td>\n    </tr>\n    <tr>\n      <th>27458</th>\n      <td>Vole</td>\n      <td>Strait_of_Malacca</td>\n      <td>1</td>\n      <td>8.0</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>102.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>26961</th>\n      <td>University_of_Chicago</td>\n      <td>Reggaeton</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>64.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4153</th>\n      <td>Bob_Marley</td>\n      <td>Earth</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>33.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>9887</th>\n      <td>Florida</td>\n      <td>The_Championships%2C_Wimbledon</td>\n      <td>1</td>\n      <td>8.0</td>\n      <td>0.000000</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>111.0</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_combinations.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:55:35.264763Z",
     "start_time": "2023-11-16T14:55:34.854377200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      first_article  count\n1824      Jerusalem     10\n2995       Pellagra      6\n997        Conflict     15\n2321  Morecambe_Bay      8\n2188     Canterbury      9",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>first_article</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1824</th>\n      <td>Jerusalem</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2995</th>\n      <td>Pellagra</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>Conflict</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>2321</th>\n      <td>Morecambe_Bay</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2188</th>\n      <td>Canterbury</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_sources.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:55:35.360895800Z",
     "start_time": "2023-11-16T14:55:34.873288900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                  last_article  count\n1536               Romanticism     10\n2330                       RER      6\n2201                 Oligarchy      7\n2553  Great_Spotted_Woodpecker      6\n1526             Volcanic_pipe     10",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>last_article</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1536</th>\n      <td>Romanticism</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2330</th>\n      <td>RER</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2201</th>\n      <td>Oligarchy</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2553</th>\n      <td>Great_Spotted_Woodpecker</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1526</th>\n      <td>Volcanic_pipe</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_targets.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Semantic Similarity\n",
    "\n",
    "An important part of the project is to study how humans and machines move from article to article. Semantic similarity compares two strings based on a trained model and assigns a value according to how are they correlated (the higher, the more related). For example, 'king' and 'queen' will have a higher semantic similarity than say, 'king' and 'chemistry' (will prove this here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the underscore and decode the url\n",
    "\n",
    "First we define a function that corrects the strings to have a readable format. For example, '%C3%89douard_Manet' is transformed to 'Édouard Manet'.\n",
    "\n",
    "We will create a function to decode a word, and we will be able to use it in series and dataframes using apply()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:55:35.440893300Z",
     "start_time": "2023-11-16T14:55:34.896452900Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_word(word):\n",
    "    word = word.replace('_', ' ')\n",
    "    return unquote(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:55:35.594290300Z",
     "start_time": "2023-11-16T14:55:34.903899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    %C3%81ed%C3%A1n_mac_Gabr%C3%A1in\n1                          %C3%85land\n2                  %C3%89douard_Manet\n3                           %C3%89ire\n4          %C3%93engus_I_of_the_Picts\nName: articles, dtype: object"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles['articles'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:55:35.594290300Z",
     "start_time": "2023-11-16T14:55:34.919168900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0        Áedán mac Gabráin\n1                    Åland\n2            Édouard Manet\n3                     Éire\n4    Óengus I of the Picts\nName: articles, dtype: object"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles['articles'].apply(decode_word).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Distance Model\n",
    "We create a function that returns the semantic similarity between two words you provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:55:38.924468700Z",
     "start_time": "2023-11-16T14:55:34.938951600Z"
    }
   },
   "outputs": [],
   "source": [
    "# We define the model outside the function (make sure to run this before using the function)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:55:38.962309400Z",
     "start_time": "2023-11-16T14:55:38.931665800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to get embeddings (just because we will use it in semantic similarity function)\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "# Semantic similarity function\n",
    "def semantic_similarity(word1, word2):\n",
    "    embedding1 = get_embedding(word1)\n",
    "    embedding2 = get_embedding(word2)\n",
    "    return cosine_similarity(embedding1.detach().numpy(), embedding2.detach().numpy())[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:55:39.101532500Z",
     "start_time": "2023-11-16T14:55:38.937435800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.9388243"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_similarity('king', 'queen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:55:39.246128200Z",
     "start_time": "2023-11-16T14:55:39.096147800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.6550222"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_similarity('king', 'chemistry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Distance Matrix\n",
    "Provided a series, it creates a df where indices and column names are the strings of the series, and fills the matrix with the semantic similarity between all words in the provided series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:55:39.246128200Z",
     "start_time": "2023-11-16T14:55:39.207950Z"
    }
   },
   "outputs": [],
   "source": [
    "def semantic_similarity_matrix(titles):\n",
    "    df = pd.DataFrame(index=titles, columns=titles)\n",
    "    for i in range(len(titles)):\n",
    "        for j in range(i+1, len(titles)):\n",
    "            embedding1 = get_embedding(titles[i])\n",
    "            embedding2 = get_embedding(titles[j])\n",
    "            similarity = cosine_similarity(embedding1.detach().numpy(), embedding2.detach().numpy())[0][0]\n",
    "            df.iloc[i, j] = similarity\n",
    "            df.iloc[j, i] = similarity  # Copy value to lower triangle\n",
    "            np.fill_diagonal(df.values, 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:55:39.823616100Z",
     "start_time": "2023-11-16T14:55:39.214764200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "               king     queen chemistry   biology\nking              1  0.938824  0.655022  0.734002\nqueen      0.938824         1  0.633365  0.745616\nchemistry  0.655022  0.633365         1  0.846376\nbiology    0.734002  0.745616  0.846376         1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>king</th>\n      <th>queen</th>\n      <th>chemistry</th>\n      <th>biology</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>king</th>\n      <td>1</td>\n      <td>0.938824</td>\n      <td>0.655022</td>\n      <td>0.734002</td>\n    </tr>\n    <tr>\n      <th>queen</th>\n      <td>0.938824</td>\n      <td>1</td>\n      <td>0.633365</td>\n      <td>0.745616</td>\n    </tr>\n    <tr>\n      <th>chemistry</th>\n      <td>0.655022</td>\n      <td>0.633365</td>\n      <td>1</td>\n      <td>0.846376</td>\n    </tr>\n    <tr>\n      <th>biology</th>\n      <td>0.734002</td>\n      <td>0.745616</td>\n      <td>0.846376</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_similarity_matrix(pd.Series(['king', 'queen', 'chemistry', 'biology']))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Basic AI\n",
    "\n",
    "Most of the model requires for there to be an AI model we can compare it against.\n",
    "\n",
    "We were indicated by the TA to not focus on this too much, as this is a data analysis course, not an ML course. Because of this, we took the implementation of A\\* that was included in networkX and created two modified versions that now do the following:\n",
    "- First version returns all of the explored nodes, not just the shortest path found\n",
    "- Second version is forced to do a depth first search without being able to return\n",
    "\n",
    "For our purposes, the explored nodes is the most interesting metric, as it describes what were the links \"clicked\".\n",
    "\n",
    "We found a paper that implements a more complicated version, and we might be able to do something with graph neural networks, but for now this is good enough.\n",
    "\n",
    "We additionally do a bit of work to show how the system works timewise, as well as how the comparison will work in the future.\n",
    "\n",
    "The time comparison is not super useful though, as that will depend on hardware too much to be worth using easily."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the modded a star that returns explored nodes:\n",
      " Found solution for Actor to Japan exploring the following number of nodes: 1\n",
      " Found it in: 1.0417146682739258\n",
      "Using depth first only A star that returns explored nodes:\n",
      " Found solution for Actor to Japan exploring the following number of nodes: 1\n",
      " Found it in: 0.6542062759399414\n"
     ]
    }
   ],
   "source": [
    "import machine_searchers\n",
    "import time\n",
    "\n",
    "def modded_get_embedding(text: str):\n",
    "    temp_str = text.replace('_', ' ')\n",
    "    temp_str = unquote(temp_str)\n",
    "    inputs = tokenizer(temp_str, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "def distance_two_words(w1: str, w2: str):\n",
    "    \"\"\"Receives a string that was in the wikispeedia dataset, and transforms it as needed to work\n",
    "    with the berd embeddings.\"\"\"\n",
    "\n",
    "    embedding1 = modded_get_embedding(w1)\n",
    "    embedding2 = modded_get_embedding(w2)\n",
    "    similarity = cosine_similarity(embedding1.detach().numpy(), embedding2.detach().numpy())[0][0]\n",
    "    # Adding absolute, just in case it is needed\n",
    "    # Similarity is actually 1 - abs(similarity) + 1,\n",
    "    # As we want closer words to have a smaller distance\n",
    "    # The last plus one is to indicate that there would be an extra cost to exploring, as if not the system often\n",
    "    # thinks that there are nodes that have a distance of 0.5 or something like that\n",
    "    similarity = 1 - abs(similarity) + 1\n",
    "    # print(\"First word:\", w1, \". Second word:\", w2, \". GoodDistance:\", similarity)\n",
    "    return similarity\n",
    "\n",
    "start_time = time.time()\n",
    "lib_path_1, lib_explore_1 = machine_searchers.modded_astar_path(wikispeedia, 'Actor', 'Japan', heuristic=distance_two_words)\n",
    "end_time = time.time()\n",
    "\n",
    "# It's len - 1 because the target node is also included, and that node wasn't explored\n",
    "print(\"Using the modded a star that returns explored nodes:\")\n",
    "print(\" Found solution for Actor to Japan exploring the following number of nodes:\", len(lib_explore_1)-1)\n",
    "print(\" Found it in:\", end_time-start_time)\n",
    "\n",
    "start_time = time.time()\n",
    "lib_path_2, lib_explore_2 = machine_searchers.only_depth_first_astar_path(wikispeedia, 'Actor', 'Japan', heuristic=distance_two_words)\n",
    "end_time = time.time()\n",
    "\n",
    "# It's len - 1 because the target node is also included, and that node wasn't explored\n",
    "print(\"Using depth first only A star that returns explored nodes:\")\n",
    "print(\" Found solution for Actor to Japan exploring the following number of nodes:\", len(lib_explore_1)-1)\n",
    "print(\" Found it in:\", end_time-start_time)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T15:06:08.877102100Z",
     "start_time": "2023-11-16T15:06:06.972031500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we'll take the most commonly explored node pair path, run it through the two algorithms and see what is the result!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "      first_article last_article  count  mean_length  std_length  mean_rating  \\\n2318       Asteroid       Viking   1043     7.516779    3.019205     2.554455   \n4427          Brain    Telephone   1040     7.100000    3.580183     2.482051   \n25700       Theatre        Zebra    905     7.836464    3.849462     2.635359   \n21255       Pyramid         Bean    642     8.246106    4.259726     2.677419   \n3206         Batman         Wood    148     7.263514    3.413382     2.851852   \n\n       std_rating  mean_durationInSec  std_durationInSec  \n2318     0.980963          202.216683         281.960852  \n4427     1.043248          174.138462         189.381553  \n25700    1.044531          251.068508        1169.866464  \n21255    1.010459          199.085670         191.480244  \n3206     1.199478          113.466216         141.024406  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>first_article</th>\n      <th>last_article</th>\n      <th>count</th>\n      <th>mean_length</th>\n      <th>std_length</th>\n      <th>mean_rating</th>\n      <th>std_rating</th>\n      <th>mean_durationInSec</th>\n      <th>std_durationInSec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2318</th>\n      <td>Asteroid</td>\n      <td>Viking</td>\n      <td>1043</td>\n      <td>7.516779</td>\n      <td>3.019205</td>\n      <td>2.554455</td>\n      <td>0.980963</td>\n      <td>202.216683</td>\n      <td>281.960852</td>\n    </tr>\n    <tr>\n      <th>4427</th>\n      <td>Brain</td>\n      <td>Telephone</td>\n      <td>1040</td>\n      <td>7.100000</td>\n      <td>3.580183</td>\n      <td>2.482051</td>\n      <td>1.043248</td>\n      <td>174.138462</td>\n      <td>189.381553</td>\n    </tr>\n    <tr>\n      <th>25700</th>\n      <td>Theatre</td>\n      <td>Zebra</td>\n      <td>905</td>\n      <td>7.836464</td>\n      <td>3.849462</td>\n      <td>2.635359</td>\n      <td>1.044531</td>\n      <td>251.068508</td>\n      <td>1169.866464</td>\n    </tr>\n    <tr>\n      <th>21255</th>\n      <td>Pyramid</td>\n      <td>Bean</td>\n      <td>642</td>\n      <td>8.246106</td>\n      <td>4.259726</td>\n      <td>2.677419</td>\n      <td>1.010459</td>\n      <td>199.085670</td>\n      <td>191.480244</td>\n    </tr>\n    <tr>\n      <th>3206</th>\n      <td>Batman</td>\n      <td>Wood</td>\n      <td>148</td>\n      <td>7.263514</td>\n      <td>3.413382</td>\n      <td>2.851852</td>\n      <td>1.199478</td>\n      <td>113.466216</td>\n      <td>141.024406</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So it's finding the length between asteroid and viking\n",
    "article_combinations.sort_values('count', ascending=False).head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T15:19:17.361246400Z",
     "start_time": "2023-11-16T15:19:17.158843400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the modded a star that returns explored nodes:\n",
      " Found solution for Asteroid to Viking exploring the following number of nodes: 52\n",
      "Path length was: 3\n",
      " Found it in: 80.1152811050415\n",
      "Using depth first only A star that returns explored nodes:\n",
      " Found solution for Asteroid to Viking exploring the following number of nodes: 40\n",
      "Path length was: 40\n",
      " Found it in: 510.53669261932373\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "lib_path_1, lib_explore_1 = machine_searchers.modded_astar_path(wikispeedia, 'Asteroid', 'Viking', heuristic=distance_two_words)\n",
    "end_time = time.time()\n",
    "\n",
    "# It's len - 1 because the target node is also included, and that node wasn't explored\n",
    "print(\"Using the modded a star that returns explored nodes:\")\n",
    "print(\" Found solution for Asteroid to Viking exploring the following number of nodes:\", len(lib_explore_1)-1)\n",
    "print(\"Path length was:\", len(lib_path_1)-1)\n",
    "print(\" Found it in:\", end_time-start_time)\n",
    "\n",
    "start_time = time.time()\n",
    "lib_path_2, lib_explore_2 = machine_searchers.only_depth_first_astar_path(wikispeedia, 'Asteroid', 'Viking', heuristic=distance_two_words)\n",
    "end_time = time.time()\n",
    "print('')\n",
    "\n",
    "# It's len - 1 because the target node is also included, and that node wasn't explored\n",
    "print(\"Using depth first only A star that returns explored nodes:\")\n",
    "print(\" Found solution for Asteroid to Viking exploring the following number of nodes:\", len(lib_explore_2)-1)\n",
    "print(\"Path length was:\", len(lib_path_2)-1)\n",
    "print(\" Found it in:\", end_time-start_time)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T15:32:21.966890100Z",
     "start_time": "2023-11-16T15:22:31.309855Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "['Asteroid', '1_Ceres', 'Paris', 'Viking']"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib_path_1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T15:33:23.473883500Z",
     "start_time": "2023-11-16T15:33:23.173630700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, based on the previous example of the path, this works out well enough. The systems spends a lot of time exploring and going back, which might be a common issue. There is a huge disconnect between explored and actual path length, but that is common for A\\*, so it's an expected caveat.\n",
    "\n",
    "It is interesting to note that the optimal solution passed through Paris, which seems to fit the definition of being one of the hubs that are described in the paper. Maybe the hub strategy is actually useful in most cases!\n",
    "\n",
    "The depth first method took a lot longer to run than planned. Based on this, it might be worth considering other alternatives.\n",
    "\n",
    "But still, at least we've proven the model works, and can give results that we can compare against humans. Again, this is using a much simpler method, but this could be enhanced in the future."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
